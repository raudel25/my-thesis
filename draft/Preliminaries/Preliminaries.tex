\documentclass[12pt]{article}

\usepackage[utf8]{inputenc} % Permite escribir caracteres especiales directamente
\usepackage[spanish]{babel} % Configura el idioma a español

\usepackage{amsmath}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage[lmargin=2cm,rmargin=5cm]{geometry}
\usepackage{amsfonts}


\input{word-comments.tex}

\usepackage{amsthm}
\newtheorem{theorem}{Teorema}
\newtheorem{lemma}{Lema}
\newtheorem{definition}{Definición}


\parskip=5pt

\title{Preliminares}
\author{Raudel Alejandro Gómez Molina}

\begin{document}

\maketitle

% \chapter{Preliminares}
% \label{chap:preliminaries}

% \chapter{Gramáticas de concatenación de rango}
% \label{chap:RCG}

% \chapter{Lenguaje de las fórmulas booleanas satisfacibles empleando transducción finita}
% \label{chap:LSATFT}

% \chapter{Lenguaje de las fórmulas booleanas satisfacibles empleando gramáticas de concatenación de rango}
% \label{chap:LSATRCG}

En este capítulo se presentan las principales definiciones y conceptos que serán usados en el resto del trabajo, además
se analizan las investigaciones anteriores que exponen estrategias de solución del problema de la satisfacibilidad
booleana  mediante formalismos de la teoría de lenguajes.

\section{Teoría de Lenguajes}

En esta sección se presentan los principales conceptos de teoría de lenguajes que sirven de base al contenido de los capítulos y secciones posteriores.

\subsection{Conceptos básicos, operaciones y problemas relacionados con lenguajes}

Los conceptos básicos de la teoría de lenguajes formales son: alfabeto, cadena y lenguaje. Un alfabeto, denotado 
como $\Sigma$, es un conjunto finito y no vacío de símbolos; una cadena es una sucesión finita de símbolos del alfabeto y 
un lenguaje es un conjunto de cadenas definido sobre un alfabeto. Por ejemplo, el 
alfabeto $\Sigma=\{1,0\}$ está formado por los símbolos 0 y 1, $11$ y $101$ son cadenas sobre el alfabeto $\Sigma$ y un ejemplo de lenguaje
es  el conjunto de cadenas de 0 y 1 que terminan en 1.

El símbolo $\varepsilon$, representa la cadena vacía. Si se tiene una cadena $w$, por convenio  $w^n$ representa la cadena
resultante de concatenar $w$ $n$ veces. Si $\Sigma$ es un alfabeto, $\Sigma^{+}$ representa a todas las cadenas de uno o más 
símbolos que se pueden formar sobre $\Sigma$ y  $\Sigma^*$  representa la unión de $\Sigma^{+}$ y $\{\varepsilon\}$.

Existen varias operaciones que pueden realizarse usando alfabetos, cadenas y lenguajes. Seguidamente se presentan algunas de ellas.

Como los lenguajes son conjuntos, todas las operaciones sobre conjuntos también se definen para lenguajes: unión, intersección, complemento \cite{authomataTheory}.
La siguiente operación, homomorfismo, permite definir los transductores finitos que se usan en el capítulo \ref{chap:LSATFT} para 
construir el lenguaje de todas las fórmulas booleanas satisfacibles.

\begin{definition}
  Dados un alfabeto \( \Sigma \) y un alfabeto \( \Gamma \), un \textbf{homomorfismo} es una función:
  \[
    h: \Sigma \to \Gamma^*
  \]
  tal que:
  \begin{enumerate}
    \item Para cada \( a \in \Sigma \), \( h(a) \) es una cadena en \( \Gamma^* \), y
    \item si $w=a_1a_2\ldots a_n$ es una cadena entonces
          $$h(w)=h(a_1)h(a_2)\ldots h(a_n).$$
  \end{enumerate}
\end{definition}

Por ejemplo, si sobre el alfabeto $\Sigma=\{a,b\}$ se define el homomorfismo $h$, tal que $h(a)=0$ y $h(b)=11$, entonces
$h(ab)=011$.

El lenguaje que se obtiene como resultado de aplicarle un homomorfismo $h$, sobre todas las cadenas de un lenguaje $L$ se define como:
$$L_h=\{h(w)\mid w\in L\}.$$
Por ejemplo el lenguaje que se obtiene de aplicarle el homomorfismo anterior al lenguaje $$L=\{a^nb^n\mid n\in \mathbb{N}\},$$ es el lenguaje
$$L_h=\{0^n1^{2n}\mid n\in \mathbb{N}\}.$$

Una vez que se tiene definido un lenguaje es posible responder preguntas como si una cadena dada pertenece al lenguaje, o si el lenguaje es vacío o contiene algún elemento.
Estos problemas se usan en los capítulos \ref{chap:LSATFT} y \ref{chap:LSATRCG} para determinar si una fórmula booleana
es satisfacible y en los trabajos \cite{aCFSAT} y \cite{aSRCSAT} para determinar si una fórmula booleana con ciertas restricciones es 
satisfacible o no.

\begin{definition}
  El \textbf{problema de la palabra} consiste en determinar si una cadena pertenece a un lenguaje dado. 
\end{definition}
Por ejemplo, dado el lenguaje $L=\{w\,|\,\text{last}(w)=0\}$, determinar si $1100100$ pertenece a $L$.

Todo problema en Ciencia de la Computación se puede reducir a un problema de la palabra, 
ya que cualquier problema se puede codificar como un lenguaje formal \cite{authomataTheory}. Este planteamiento
se utiliza en el capítulo \ref{chap:LSATRCG}, para demostrar que las gramáticas de concatenación de rango
reconocen todos los problemas de la clase NP-Completo. Las gramáticas de concatenación de rango se definen en el 
capítulo \ref{chap:RCG} y la clase NP-Completo se define en la sección \ref{sec:problemsCategory}.

\begin{definition} 
  El \textbf{problema del vacío} consiste en determinar si un lenguaje es vacío.
\end{definition}
Por ejemplo, determinar si el lenguaje formado por los números pares mayores que 5, que son primos es vacío, o si el conjunto formado por todas las interpretaciones que hagan verdadera a una fórmula booleana es vacío o no.

En la siguiente sección se definen las gramáticas, un mecanismo que permite generar los elementos de un lenguaje.

\subsection{Gramáticas}
\label{sec:grammars}

\begin{definition}
  Una \textbf{gramática} es un formalismo utilizado para describir lenguajes formales. Se define como una 4-tupla:
  \[
    G = (N, \Sigma, P, S),
  \]
  donde:
  \begin{itemize}
    \item \(N\): Es un conjunto finito de \textbf{símbolos no terminales}.
    \item \(\Sigma\): Es un conjunto finito de \textbf{símbolos terminales}, que constituyen el alfabeto sobre el que se construyen las cadenas del lenguaje. Se cumple que \(N \cap \Sigma = \emptyset\).
    \item \(P\): Es un conjunto finito de \textbf{reglas de producción} de la forma:
          \[
            \alpha \to \beta, \quad \text{donde } \alpha \in (N \cup \Sigma)^* \;\text{y}\; \beta \in (N \cup \Sigma)^*.
          \]
          
    \item \(S\): Es el \textbf{símbolo inicial}, \(S \in N\), que define el punto de partida para derivar cadenas del lenguaje.
  \end{itemize}
\end{definition}


Una derivación en la gramática consiste en seleccionar una \textbf{regla de producción} $\alpha \to \beta$ y sustituir una ocurrencia de
$\alpha$ en una cadena $w\in (\Sigma \cup N)^+$ por $\beta$ \cite{authomataTheory}.

Una cadena $w\in\Sigma^*$  se puede generar por la gramática $G$ si existe una secuencia de derivaciones que comienza con $S$
y termina con la cadena $w$.

El lenguaje generado por una gramática \(G\) se denota como:
\[
  L(G) = \{ w \in \Sigma^* \mid S \overset{+}{\to} w \},
\]
donde \(\overset{+}{\to}\) indica una derivación uno o más pasos.

A continuación se presenta la jerarquía de Chomsky, que clasifica a los lenguajes formales de acuerdo con su poder de generación.

\subsection{Jerarquía de Chomsky}

La \textbf{Jerarquía de Chomsky} \cite{hunter2020chomsky} clasifica los lenguajes en cuatro tipos, según las restricciones en sus reglas de 
producción y la capacidad expresiva de los lenguajes que generan.

El primer tipo de gramáticas son las \textbf{Gramáticas irrestrictas}. Estas gramáticas no tienen restricciones en las reglas de producción.
Cada regla tiene la forma: \(\alpha \to \beta\), donde \(\alpha, \beta \in (N \cup \Sigma)^*\) y \(\alpha \neq \varepsilon\).
Todo lenguaje generado por una gramática irrestricta se denomina \textbf{lenguaje recursivamente enumerable}. 

El siguiente tipo en la jerarquía de Chomsky son las \textbf{Gramáticas dependientes del contexto}. En estas cada regla tiene la forma: \(\alpha A \gamma \to \alpha \beta \gamma\), donde \(A \in N\), \(\alpha, \beta, \gamma \in (N \cup \Sigma)^*\), y \(|\beta| \geq 1\).
Todo lenguaje generado por una gramática dependiente del contexto se denomina \textbf{lenguaje dependiente del contexto}.
Todo lenguaje dependiente del contexto es también un lenguaje recursivamente enumerable. 

El lenguaje de todas las fórmulas booleanas satisfacibles necesariamente es un lenguaje dependiente del contexto o un lenguaje
recursivamente enumerable. Este resultado se demuestra en el capítulo \ref{chap:LSATFT}.

A continuación le siguen las \textbf{Gramáticas libres del contexto} (\textit{CFG}). En estas cada regla tiene la forma: \(A \to \beta\), donde \(A \in N\) y \(\beta \in (N \cup \Sigma)^*\).
Todo lenguaje generado por una gramática libre del contexto se denomina \textbf{lenguaje libre del contexto}.
Todo lenguaje libre del contexto es también un lenguaje dependiente del contexto. Este tipo de lenguajes permite describir 
muchas de las propiedades que generalizan las gramáticas de concatenación de rango, las cuales se explican en el capítulo
\ref{chap:RCG}. Además, en \cite{aCFSAT} se usa una CFG para resolver instancias del problema de la satisfacibilidad booleana.

El último tipo en la jerarquía son las \textbf{Gramáticas regulares}. En estas las reglas de producción tienen la forma:
\[
  A \to aB \quad \text{o} \quad A \to a,
\]
donde \(A, B \in N\) y \(a \in \Sigma\).
Todo lenguaje generado por una gramática regular se denomina \textbf{lenguaje regular}.
Todo lenguaje regular es un lenguaje libre del contexto. Esta categoría de lenguajes está relacionada con los autómatas
finitos, los cuales se usan para definir un transductor finito, que se usa en el capítulo \ref{chap:LSATFT} para 
generar todas las fórmulas booleanas satisfacibles.

Un lenguaje $A$ es más expresivo que un lenguaje $B$ si todas las cadenas que pertenecen a $B$ también pertenecen a $A$ y existen cadenas 
que pertenecen a $A$ que no pertenecen a $B$, por ejemplo los lenguajes libres del contexto son más expresivos que los lenguajes regulares \cite{authomataTheory}. 

La diferencia entre los lenguajes de la jerarquía de Chomsky se puede ilustrar con el lenguaje \textit{Copy} sobre un alfabeto $\Sigma$, que se define como 
$L_{copy}=\{w^+\,|\,w\in Z^*\}$. 

Si se toma un caso particular de $L_{copy}$, al cual se le llama $L_{copy}^n=\{w^n\,|\,w\in Z^*\}$, se cumple que 
$L_{copy}^1$ es un lenguaje regular, mientras $L_{copy}^k\,\forall\,k\geq 2$ es un lenguaje dependiente del contexto \cite{authomataTheory}. 

En la próxima sección se presentan los autómatas asociados a cada elemento de la jerarquía de Chomsky. 

\section{Autómatas}

Un autómata es una máquina abstracta que procesa cadenas de símbolos de un alfabeto finito y determina si una 
cadena pertenece a un lenguaje \cite{authomataTheory}.

Cada gramática de la jerarquía de Chomsky tiene un autómata equivalente: los lenguajes recursivamente enumerables se reconocen por una Máquina de Turing \cite{authomataTheory}, los lenguajes dependientes del contexto se reconocen por una Máquina de Turing linealmente acotada \cite{authomataTheory}, los lenguajes libres del contexto se reconocen por un Autómata de pila \cite{authomataTheory} y los lenguajes regulares se reconocen por un Autómata regular \cite{authomataTheory}.

A continuación se presentan los autómatas finitos.

\subsection{Autómata finito}

En esta sección se definen los principales conceptos de los autómatas finitos.

\begin{definition}
  Un \textbf{autómata finito} \cite{authomataTheory} es un modelo matemático que permite reconocer si una cadena pertenece a un lenguaje regular y se define como una 5-tupla $$\mathcal{A} = (Q, \Sigma, \delta, q_0, F),$$ donde:
  
  \begin{itemize}
    \item $Q$: Es un conjunto finito de \textbf{estados}.
    \item $\Sigma$: Es el \textbf{alfabeto} finito de entrada.
    \item $\delta$: Es la \textbf{función de transición}, $\delta: Q \times \Sigma \to Q$, que define cómo el autómata cambia de estado en función del símbolo leído.
    \item $q_0 \in Q$: Es el \textbf{estado inicial} desde donde comienza la computación.
    \item $F \subseteq Q$: Es el conjunto de \textbf{estados de aceptación o estados finales}.
  \end{itemize}
\end{definition}


El autómata comienza en el estado inicial $q_0$ y procede a leer el primer símbolo de la cadena.  En cada paso, la función de transición $\delta$ determina, a partir del símbolo actual de la cadena, el siguiente estado al que debe pasar el autómata.  Si al finalizar la lectura del último símbolo de la cadena, el autómata se encuentra en un estado de aceptación $q \in F$, entonces la cadena se acepta; en caso contrario, se rechaza.

Los autómatas finitos se pueden generalizar con el concepto de transductor finito, que se presenta a continuación.

\subsection{Transductor finito}

Un transductor finito \cite{finite_transducer} es un modelo computacional que extiende los autómatas finitos al 
incluir una salida para cada transición. Esto permite que al mismo tiempo que se reconoce una cadena se obtiene otra, 
que se conoce como transducción de la primera. A continuación se describe este proceso.

\begin{definition}
  Un \textbf{transductor finito} es un autómata finito con una función de transición extendida que recibe un símbolo de la cadena de entrada y un estado, y devuelve el estado al cual pasa el transductor y un símbolo.  Como resultado de la aceptación de una cadena el transductor genera una cadena de salida formada por todos los símbolos que se obtuvieron como resultado de la función de transición en el proceso de reconocimiento.
  
  Un transductor finito se define como una 6-tupla:
  \[
    T = (Q, \Sigma, \Gamma, \delta, q_0, F),
  \]
  donde:
  \begin{itemize}
    \item \(Q\) es el conjunto finito de \textbf{estados}.
    \item \(\Sigma\) es el \textbf{alfabeto} de entrada.
    \item \(\Gamma\) es el \textbf{alfabeto} de salida.
    \item \(\delta: Q \times \Sigma \to Q \times \Gamma^*\) es la \textbf{función de transición}, que le asigna a una combinación de estado actual y símbolo de entrada a un nuevo estado y un símbolo de salida.
    \item \(q_0 \in Q\) es el \textbf{estado inicial}.
    \item \(F \subseteq Q\) es el \textbf{conjunto de estados finales}.
  \end{itemize}
\end{definition}


A modo de ejemplo, se puede definir un transductor finito $T$, que reconozca cadenas del alfabeto $\{a,b\}$ que tengan ninguna o más $a$ seguida de una o más $b$ y genere una cadena formada por una cantidad de $0$ igual a la cantidad de $a$ de la cadena original seguida de una cantidad de $1$ igual a la cantidad de $b$ de la cadena original. Ese transductor se describe de la siguiente forma.
\[
  T = (Q, \Sigma, \Gamma, \delta, q_0, F),
\]
donde:
\begin{itemize}
  \item \(Q = \{q_0, q_1, q_2\}\) es el conjunto de estados.
  \item \(\Sigma = \{a, b\}\) es el alfabeto de entrada.
  \item \(\Gamma = \{0, 1\}\) es el alfabeto de salida.
  \item \(\delta\) es la función de transición definida por:
        \[
          \begin{array}{c|c|c}
            \delta & a        & b        \\
            \hline
            q_0    & (q_0, 0) & (q_1, 1) \\
            q_1    & (q_2, 0) & (q_1, 1) \\
            q_2    & (q_2, 0) & (q_2, 1) \\
          \end{array}
        \]
        Las columnas de la tabla representan el símbolo que se lee y las filas el estado en que se encuentra el transductor, 
        los valores de la tabla son una tupla que contiene el estado al cual pasa el transductor y el símbolo que se escribe.
  \item \(q_0\) es el estado inicial.
  \item \(F = \{q_1\}\) es el conjunto de estados finales.
\end{itemize}

Para reconocer $aaaabbbbb$, primero $T$ empieza por el estado $q_0$ y el primer caracter $a$, entonces pasa al estado $q_0$ y genera un $0$.
Luego, al leer el segundo caracter $a$, se mantiene en el estado $q_0$ y genera otro $0$. Este proceso se repite hasta el quinto caracter
que es $b$, entonces pasa al estado $q_1$. Luego, al leer el sexto caracter $b$, se mantiene en el estado $q_1$ y genera un $1$. Este proceso
se repite varias veces hasta que se llega al final de la cadena, por tanto se genera la cadena $000011111$.

La función de transición para un transductor finito puede tener varias salidas para la misma entrada. O sea, si se encuentra en un estado leyendo un símbolo
puede tener la opción de moverse a 2 estados distintos escribiendo símbolos distintos o moverse hacia el mismo estado 
escribiendo símbolos distintos. En este caso la transducción de una cadena son todas las posibles cadenas que se generan
por el transductor finalizando en un estado de aceptación.

El lenguaje que se obtiene como resultado de aplicarle un transductor finito $T$, sobre todas las cadenas de un lenguaje $L$ se define como
el conjunto de todas las cadenas $w$, tales que existe una cadena $e$ para la cual se cumple que $w$ pertenece al conjunto de cadenas
que genera $T$ con la cadena $e$:
$$L_T=\{w\mid \exists e: w\in T(e) \text{ y }e\in L\}.$$

En la siguiente sección se presentan algunas propiedades de los lenguajes libres del contexto que son relevantes para este trabajo.

\section{Propiedades de los lenguajes libres del contexto}

En esta sección se presenta el lema del bombeo para lenguajes libres del contexto y se menciona que los lenguajes libres del contexto son cerrados bajo homomorfismo.

El lema del bombeo es una herramienta
que permite determinar si un lenguaje no es libre del contexto. Además,
el hecho de que los lenguajes libres del contexto sean cerrados bajo homomorfismo permiten
demostrar que muchos lenguajes no son libres del contexto.

\begin{theorem}
  \label{teo:lemBom}
  El lema del bombeo establece que si $L$ es un lenguaje libre del contexto
  existe una constante $n$ tal que para toda cadena $t\in L$, donde $|t|\geq n$, puede escribirse de la forma $t=uvwxy$ tal que:
  $|vwx|\leq n$, $vx\neq \varepsilon$ y $\forall i\geq 0\,uv^iwx^iy\in L$.  
\end{theorem}

La demostración del Teorema \ref{teo:lemBom} se realiza en \cite{authomataTheory}.

\begin{theorem}
  \label{teo:CFLh}
  Los \textbf{lenguajes libres del contexto son cerrados bajo homomorfismo}, esto
  implica que dado un lenguaje $L$ libre del contexto y un homomorfismo $h$, entonces el lenguaje
  $\{h(t)\mid t\in L\}$ es un lenguaje libre del contexto.  
\end{theorem}

La demostración del Teorema \ref{teo:CFLh} se realiza en \cite{authomataTheory}.

Todas las operaciones con lenguajes y los problemas relacionados con ellos tienen una dificultad y para medir esta dificultad
se utiliza un marco teórico llamado complejidad computacional, el cual se presenta en la próxima sección. Esta definición
es importante para analizar la dificultad del problema de la palabra para un formalismo que describa todas las fórmulas booleanas
satisfacibles.

\section{Complejidad computacional}

En esta sección se definen los principales conceptos de complejidad computacional: notación asintótica y las clases de problemas. A continuación se presenta una notación para describir el tiempo que demora un algoritmo en realizar determinado cómputo.

\subsection{Notación asintótica}

La notación asintótica se utiliza para describir el comportamiento de una función $f(n)$ a medida que $n$ crece hacia el infinito.  Seguidamente se define la notación que será utilizada en el resto del trabajo:

\begin{definition}
  Una función $g(n)$ pertenece a $O(f(n))$ si existen constantes positivas $c$ y $n_0$ tales que:
  \[
    g(n) \leq c \cdot f(n) \quad \text{para todo } n \geq n_0.
  \]
\end{definition}

Esta notación proporciona un límite superior asintótico para $g(n)$.

La notación asintótica permite describir el tiempo de ejecución de un algoritmo con respecto al número de 
operaciones básicas realizadas por un modelo formal de cómputo.  Algoritmos como determinar el mínimo y el 
máximo de un arreglo son $O(n)$, ya que necesitan realizar una cantidad $n$ de operaciones básicas en relación
con la cantidad de elementos del arreglo.

Se dice que un algoritmo tiene un tiempo polinomial si puede ejecutarse en una complejidad de $O(n^k)$, donde $n$ es el tamaño de la entrada del algoritmo y $k$
es una constante. La complejidad computacional de un problema se define como la complejidad del algoritmo más eficiente que lo resuelve en el peor caso.


En la próxima sección se presenta una clasificación de los problemas de acuerdo a su complejidad computacional.
\subsection{Clases de problemas}
\label{sec:problemsCategory}

Los problemas computacionales \cite{authomataTheory} se agrupan en diferentes clases según los recursos 
necesarios para resolverlos. En este trabajo se emplean las clases P, NP, NP-Completo y NP-Duro.

\begin{definition}
  Un problema pertenece a la clase \textbf{P} si puede resolverse en tiempo polinomial \cite{authomataTheory}.
\end{definition}

\begin{definition}
  Un problema pertenece a la clase \textbf{NP} si su solución puede verificarse en tiempo polinomial \cite{authomataTheory}.
\end{definition}

\begin{definition}
  Un problema pertenece a la clase \textbf{NP-Completo}, si pertenece a NP y además es tan difícil como cualquier otro problema en NP. Esto significa que cualquier problema en NP puede reducirse a este problema en tiempo polinomial \cite{authomataTheory}.
\end{definition}

\begin{definition}
  Un problema pertenece a la clase \textbf{NP-Duro}, si es tan difícil como cualquier otro problema en NP, pero no necesariamente pertenece a NP \cite{authomataTheory}. 
\end{definition}

La relación entre las clases P y NP es uno de los problemas abiertos más importantes en la teoría de la computación 
\cite{authomataTheory}. Hasta la fecha, se desconoce si $\text{P} = \text{NP}$ o si $\text{P} \neq \text{NP}$, es decir, 
no se conoce si realmente los problemas en NP son más difíciles que los problemas en P. Por otro lado, el conjunto de 
problemas NP-Completo brinda una base sólida para el problema anterior, ya que dada su definición, cualquier problema 
perteneciente a este conjunto que sea soluble en tiempo polinomial implica que todos los problemas en NP lo son. 
Mientras que los problemas en NP-Duro pueden resultar aún más difíciles. 

A continuación se presenta el problema de la satisfacibilidad booleana, que sirve de base a los problemas de la clase NP-Completo.

\section{Problema de la satisfacibilidad booleana}

El problema de la satisfacibilidad booleana (\textit{SAT}), es un problema fundamental en la teoría de la computación y la lógica matemática \cite{authomataTheory}. El objetivo es determinar si existe una asignación de valores a las variables de una fórmula booleana tal que la expresión sea verdadera.

A continuación se presentan los principales elementos del SAT: variables, literales, cláusula, fórmulas en forma normal conjuntiva y fórmulas booleanas equivalentes.

\begin{itemize}
  \item \textbf{Variables booleanas:}
        Una variable booleana es una variable que puede tomar uno de dos valores posibles: \textit{true} (verdadero) o \textit{false} (falso). Estas variables se utilizan para construir expresiones lógicas.
  \item \textbf{Literales:}
        Un literal es una variable booleana o su negación. Formalmente, si \( x \) es una variable booleana, entonces \( x \) y \( \neg x \) (la negación de \( x \)) son literales. Un literal puede tomar los valores \( true \) o \( false \) dependiendo de la asignación de valores a las variables.
  \item  \textbf{Cláusulas:}
        Una cláusula es una disyunción (operador \textbf{OR}) de uno o más literales. Por ejemplo, la cláusula \( (x \vee \neg y \vee z) \) es una disyunción de tres literales: \( x \), \( \neg y \) y \( z \). Una cláusula es verdadera si al menos uno de sus literales es verdadero. Si todos los literales son falsos, la cláusula será falsa.
  \item \textbf{Fórmulas en forma normal conjuntiva:}
        Una fórmula booleana en forma normal conjuntiva (\textit{CNF}) es una conjunción (operador \textbf{AND}) de cláusulas. En otras palabras, es una expresión booleana que se puede escribir como una serie de cláusulas unidas por el operador \textbf{AND}. Por ejemplo:        
        \[
          (x \vee \neg y \vee z) \wedge (\neg x \vee y) \wedge (x \vee \neg z).
        \]
  \item \textbf{Fórmulas booleanas equivalentes:}
        Dos fórmulas booleanas se consideran equivalentes si, para cualquier asignación de valores a sus variables, ambas producen el mismo resultado lógico. Por ejemplo, las fórmulas \( x \vee (y \wedge z) \) y \( (x \vee y) \wedge (x \vee z) \) son equivalentes, ya que para cualquier combinación de valores \( x, y, z \), ambas tienen el mismo valor lógico.
        
        Para cualquier fórmula booleana existe una fórmula booleana equivalente en CNF \cite{authomataTheory} y 
        el algoritmo para encontrarla es polinomial, por lo tanto se puede asumir que toda fórmula booleana está en CNF.
        
\end{itemize}

\begin{definition}  
  El problema de la \textbf{satisfacibilidad booleana}, o SAT, consiste en determinar si existe una asignación de valores \( true \) o \( false \) a las variables de una fórmula booleana, tal que la fórmula completa sea verdadera. 
\end{definition}

Una fórmula booleana en CNF es satisfacible si existe una asignación de valores a las variables tal que todas las cláusulas de la fórmula sean verdaderas simultáneamente.
Si existe tal asignación, la fórmula es \textit{satisfacible}. Si no existe tal asignación, la fórmula no es \textit{satisfacible}.

\subsection{SAT como problema NP-Completo y variantes polinomiales}

El SAT es el primer problema demostrado como NP-Completo \cite{authomataTheory} y juega un rol central en la teoría de la complejidad computacional. Se define en la clase NP porque dada una asignación de valores a las variables de la fórmula booleana, se puede verificar en tiempo polinomial si dicha asignación satisface la fórmula.

Además, la prueba de que SAT es NP-Completo fue una de las contribuciones principales de Stephen Cook en 1971 \cite{Cook1971}, marcando el inicio de la teoría de la NP-Completitud.

Un SAT con exactamente $n$ variables distintas en cada cláusula se denomina $n$-SAT. Para el problema 2-SAT existe una solución polinomial que determina si la fórmula booleana es satisfacible o no \cite{2satbib}, pero para el problema 3-SAT no se conoce ningún algoritmo polinomial que permita
determinar si una fórmula booleana es satisfacible o no \cite{authomataTheory}.

Cualquier fórmula booleana del problema $n$-SAT se puede reducir a una fórmula booleana equivalente del problema 3-SAT,
por lo tanto, SAT es equivalente a 3-SAT en términos de complejidad computacional \cite{authomataTheory}.

Aunque no se conoce ningún algoritmo polinomial para resolver el problema SAT en general,
existen casos particulares del problema que sí pueden ser resueltos en tiempo polinomial como el 2-SAT, Horn-SAT, y XOR-SAT.


El problema \textbf{2-SAT} es una instancia de SAT donde cada cláusula contiene exactamente dos literales.  Este problema puede ser resuelto en tiempo polinomial mediante una modelación basada en grafos, utilizando algoritmos como la detección de componentes fuertemente conexas en el grafo de implicación \cite{2satbib}.

El problema \textbf{Horn-SAT} es una instancia de SAT, donde cada cláusula tiene a lo sumo un literal positivo.  Este problema puede ser resuelto en tiempo polinomial mediante el algoritmo de resolución de Horn \cite{hornsatbib}.

El problema \textbf{XOR-SAT} es una instancia de SAT donde cada cláusula representa una operación XOR sobre los literales. Puede ser resuelto en tiempo polinomial transformando el problema en un sistema de ecuaciones lineales modulares y aplicando eliminación de Gauss \cite{xorsatbib}.

En este trabajo se propone resolver el SAT usando elementos de la teoría de lenguajes, en la siguiente sección se 
presentan 2 trabajos que siguen esta idea.

\section{Solución de instancias del SAT en tiempo polinomial usando teoría de lenguajes}

Como parte del estudio del problema SAT, en la Facultad de Matemática y Computación de la Universidad de La Habana
se han desarrollado 2 trabajos: \cite{aCFSAT} y \cite{aSRCSAT}, utilizando un enfoque basado en formalismos de la teoría de lenguajes, buscando resolver 
instancias específicas del SAT, que tienen una solución polinomial.

La idea principal que se aborda en \cite{aCFSAT} consta de tres partes: asumir que todas las variables en la fórmula son distintas, construir un autómata finito que reconozca cadenas de 0 y 1 que hagan verdadera esa fórmula (asumiendo que todas las variables son distintas), y por último intersectar ese lenguaje regular con un lenguaje libre del contexto que garantice que todas las instancias de la misma variable tenga el mismo valor. Luego de esos tres pasos, se obtiene un lenguaje libre del contexto formado por las cadenas de 0 y 1 que satisfacen la fórmula y que además respeta los valores de las variables duplicadas.

Para determinar si la fórmula es satisfacible o no, se comprueba si el lenguaje es vacío, que en el caso de los lenguajes libres del contexto tiene una complejidad $O(n)$. Todo el algoritmo descrito anteriormente tiene una complejidad que es O($n^3$), donde $n$ es el tamaño de la fórmula booleana.

El autómata finito diseñado en \cite{aCFSAT}, se denominó \textbf{autómata booleano}. La idea detrás de este es representar las reglas de la lógica proposicional en las transiciones entre los estados de un autómata finito, donde cada estado del autómata representa un valor de verdad positivo o negativo que significa que hasta ese momento (solo tomando las instancias de las variables asociadas a los caracteres reconocidos) la fórmula se evalúa positiva o negativa respectivamente \cite{aCFSAT}.

En \cite{aSRCSAT} se generaliza la idea de \cite{aCFSAT}, pero esta vez el autómata booleano asociado a la fórmula booleana se intersecta con una gramática de concatenación de rango simple \cite{mainRCGBib}, lo cual permite ampliar el conjunto de fórmulas booleanas que pueden resolverse usando esta estrategia. Las gramáticas concatenación de rango simple son un caso particular de las gramáticas de concatenación de rango, y estas se presentan en el próximo capítulo, porque se usan en el capítulo \ref{chap:LSATRCG} para construir una gramática que 
describa el lenguaje de las fórmulas booleanas satisfacibles.

En el presente trabajo se sigue otro enfoque para resolver el SAT usando teoría de lenguajes: en vez de resolver el problema del vacío para el lenguaje de todas las interpretaciones que hacen verdadera a una fórmula dada, se construye el lenguaje de todas las fórmulas booleanas satisfacibles y para determinar si un SAT es satisfacible se comprueba si pertenece a ese lenguaje.

Lo anterior permite demostrar que para muchos formalismos el problema de la palabra es NP-Duro (los que sean cerrados bajo transducción finita y generen una variante de $L_{copy}$).

Como parte de este trabajo también se obtiene una gramática de concatenación de rango que reconoce las fórmulas booleanas satisfacibles. A partir de la gramática que reconoce el lenguaje de todas las fórmulas booleanas satisfacibles, se puede demostrar que las gramáticas de concatenación de rango abarcan todos los problemas que pertenecen a la clase NP.

En el siguiente capítulo se presentan las gramáticas de concatenación de rango.

\begin{thebibliography}{99}
  
  \bibitem{mainRCGBib}
  Boullier, Pierre. 
  \textit{Proposal for a Natural Language Processing Syntactic Backbone}. 
  Research Report RR-3342, INRIA, 1998. 
  
  \bibitem{propertiesRCGBib}
  Boullier, Pierre. 
  \textit{A Cubic Time Extension of Context-Free Grammars}. 
  Research Report RR-3611, INRIA, 1999. 
  
  \bibitem{simpleMatrixLanguages}
  Ibarra, Oscar H. 
  \textit{Simple matrix languages}. 
  \textit{Information and Control}, Vol. 17, No. 4, pp. 359-394, 1970. 
  
  \bibitem{globalIndexLanguages}
  Castaño, José M. 
  \textit{Global Index Languages}. 
  Ph.D. Thesis, The Faculty of the Graduate School of Arts and Sciences, Brandeis University, 2004.
  
  \bibitem{authomataTheory}
  Hopcroft, John E., Motwani, Rajeev, y Ullman, Jeffrey D. 
  \textit{Introduction to Automata Theory, Languages, and Computation}. 
  3ª edición, Addison-Wesley, 2006. ISBN: 9780321455369.
  
  \bibitem{aCFSAT}
  Fernández Arias, Alina. 
  \textit{El problema de la satisfacibilidad booleana libre del contexto}. 
  Facultad de Matemática y Computación, Universidad de La Habana, 2007.
  
  \bibitem{aSRCSAT}
  Aguilera López, Manuel. 
  \textit{Problema de la Satisfacibilidad Booleana de Concatenación de Rango Simple}. 
  Facultad de Matemática y Computación, Universidad de La Habana, 2016.
  
  \bibitem{aSMSAT}
  Rodríguez Salgado, José Jorge. 
  \textit{Gramáticas Matriciales Simples. Primera aproximación para una solución al problema SAT}. 
  Facultad de Matemática y Computación, Universidad de La Habana, 2019.
  
  \bibitem{2satbib}
  Steven Halim and Felix Halim. 
  \textit{Competitive Programming 3: The New Lower Bound of Programming Contests}. 
  Lulu.com, 2013.
  
  \bibitem{finite_transducer}
  Calude, Cristian and Salomaa, Kai and Roblot, Tania.
  \textit{Finite-State Complexity and the Size of Transducers}. 
  Open Publishing Association. 
  
  
  
\end{thebibliography}


\end{document}