\documentclass{article}

\usepackage[utf8]{inputenc} % Permite escribir caracteres especiales directamente
\usepackage[spanish]{babel} % Configura el idioma a español

\usepackage{amsmath}
\usepackage{tikz}
\usepackage{xcolor}

\title{Preliminares}
\author{Raudel Alejandro Gómez Molina}

\begin{document}

\maketitle

\section{Teoría de Lenguajes}

\subsection{Conceptos básicos}

\paragraph{Alfabeto:} Un alfabeto, denotado como $\Sigma$, es un conjunto finito y no vacío de símbolos, ejemplo:
$$\Sigma=\{1,0\}$$
\paragraph{Cadena:} Una cadena es una sucesión finita de símbolos del alfabeto, ejemplo: la representación binaria de
los números $3=11$ y $5=101$ puede ser un ejemplo de cadena sobre el alfabeto $\Sigma$ anteriormente
definido.
\paragraph{Lenguaje:} Un lenguaje es un conjunto de cadenas definido sobre un alfabeto, ejemplo: el lenguaje de la
representación binaria de todos los números pares $L=\{w\,|\,\text{last}(w)=0\}$, $\text{last}(w)$
representa el último caracter de la cadena $w$.

\subsection{Operaciones con Lenguajes}

\paragraph{Unión:} La unión de dos lenguajes $L_1$ y $L_2$ se define como el conjunto de cadenas que
pertenecen a $L_1$ o a $L_2$:
$$L_1\cup L_2=\{w\,|\,w\in L_1\,\vee\,w\in L_2\}$$
\paragraph{Intersección:} La intersección de dos lenguajes $L_1$ y $L_2$ se define como el conjunto de
cadenas que pertenecen a $L_1$ y a $L_2$:
$$L_1\cap L_2=\{w\,|\,w\in L_1\,\wedge\,w\in L_2\}$$
\paragraph{Concatenación:} La concatenación de dos lenguajes $L_1$ y $L_2$ se define como el conjunto
de cadenas que resultan de concatenar una cadena de $L_1$ con una cadena de $L_2$:
$$L_1\circ L_2=\{w_1w_2\,|\,w_1\in L_1\,\wedge\,w_2\in L_2\}$$
\paragraph{Complemento:} El complemento de un lenguaje $L$ se define como el conjunto de cadenas que no
pertenecen a $L$:
$$\overline{L}=\{w\,|\,w\notin L\}$$
\paragraph{Estrella de Kleene:} La estrella de Kleene de un lenguaje $L$ se define como el conjunto de
cadenas que resultan de concatenar cero o más cadenas de $L$:
$$L^*=\{w_1w_2\ldots w_n\,|\,n\geq 0\,\text{y}\,w_i\in L\}$$

\subsection{Problemas relacionados con Lenguajes}

\paragraph{Problema de la palabra:} Consiste en determinar si una cadena pertenece a un lenguaje dado. Todo problema en Ciencias de la Computación puede ser reducido a un problema de la palabra, ya que cualquier problema
puede ser codificado como un lenguaje formal.
\paragraph{Problema del vacío:} Consiste en determinar si un lenguaje es vacío.
\paragraph{Problema de la finitud:} Consiste en determinar si un lenguaje es finito.
\paragraph{Problema de la equivalencia:} Consiste en determinar si dos $L_1$ y $L_2$ lenguajes son iguales (es decir si se cumple que
$L_1\subseteq L_2 \wedge L_2\subseteq L_1$).

\subsection{Gramáticas}

Una \textbf{gramática} es un sistema matemático utilizado para describir lenguajes formales. Se define como una 4-tupla:
\[
      G = (N, \Sigma, P, S),
\]
donde:
\begin{itemize}
      \item \(N\): Es un conjunto finito de \textbf{símbolos no terminales}, que representan variables o categorías intermedias.
      \item \(\Sigma\): Es un conjunto finito de \textbf{símbolos terminales}, que constituyen el alfabeto del lenguaje. Se cumple que \(N \cap \Sigma = \emptyset\).
      \item \(P\): Es un conjunto finito de \textbf{reglas de producción}, cada una de la forma:
            \[
                  \alpha \to \beta, \quad \text{donde } \alpha \in (N \cup \Sigma)^* \wedge \beta \in (N \cup \Sigma)^*.
            \]
      \item \(S\): Es el \textbf{símbolo inicial}, \(S \in N\), que define el punto de partida para derivar cadenas del lenguaje.
\end{itemize}

El lenguaje generado por una gramática \(G\) se denota como:
\[
      L(G) = \{ w \in \Sigma^* \mid S \overset{*}{\Rightarrow} w \},
\]
donde \(\overset{*}{\Rightarrow}\) indica una derivación en cero o más pasos.

\subsection{Jerarquía de Chomsky}

La \textbf{Jerarquía de Chomsky} (Figura~\ref{fig:ChomskySchema}) clasifica las gramáticas en cuatro tipos, según las restricciones en sus reglas de producción y la capacidad expresiva de los lenguajes que generan.

\begin{enumerate}
      \item \textbf{Tipo 0: Gramáticas irrestrictas}
            \begin{itemize}
                  \item No tienen restricciones en las reglas de producción.
                  \item Cada regla tiene la forma: \(\alpha \to \beta\), donde \(\alpha, \beta \in (N \cup \Sigma)^*\) y \(\alpha \neq \varepsilon\).
                  \item Generan los \textbf{lenguajes recursivamente enumerables}.
            \end{itemize}

      \item \textbf{Tipo 1: Gramáticas sensibles al contexto}
            \begin{itemize}
                  \item Cada regla tiene la forma: \(\alpha A \gamma \to \alpha \beta \gamma\), donde \(A \in N\), \(\alpha, \beta, \gamma \in (N \cup \Sigma)^*\), y \(|\beta| \geq 1\).
                  \item Generan los \textbf{lenguajes sensibles al contexto}.
            \end{itemize}

      \item \textbf{Tipo 2: Gramáticas libres de contexto}
            \begin{itemize}
                  \item Cada regla tiene la forma: \(A \to \beta\), donde \(A \in N\) y \(\beta \in (N \cup \Sigma)^*\).
                  \item Generan los \textbf{lenguajes libres de contexto}.
            \end{itemize}

      \item \textbf{Tipo 3: Gramáticas regulares}
            \begin{itemize}
                  \item Las reglas tienen la forma:
                        \[
                              A \to aB \quad \text{o} \quad A \to a,
                        \]
                        donde \(A, B \in N\) y \(a \in \Sigma\).
                  \item Generan los \textbf{lenguajes regulares}.
            \end{itemize}
\end{enumerate}


\begin{figure}
      \centering
      \begin{tikzpicture}[scale=1]
            \draw[thick, fill=red!20] (0,0) ellipse (4cm and 2cm);
            \node at (0,1.7) {\textbf{\textcolor{red!70!black}{Tipo 0}}};

            \draw[thick, fill=blue!20] (0,0) ellipse (3cm and 1.5cm);
            \node at (0,1.2) {\textbf{\textcolor{blue!70!black}{Tipo 1}}};

            \draw[thick, fill=green!20] (0,0) ellipse (2cm and 1cm);
            \node at (0,0.7) {\textbf{\textcolor{green!70!black}{Tipo 2}}};

            \draw[thick, fill=yellow!20] (0,0) ellipse (1cm and 0.5cm);
            \node at (0,0) {\textbf{\textcolor{yellow!70!black}{Tipo 3}}};
      \end{tikzpicture}
      \caption{Esquema de la Jerarquía de Chomsky}
      \label{fig:ChomskySchema} %
\end{figure}

\section{Complejidad computacional}

\subsection{Máquina de Turing}

Una Máquina de Turing \cite{authomataTheory} es un modelo abstracto de computación universal introducido por Alan Turing en 1936. Este modelo consiste en los siguientes componentes:

\begin{itemize}
      \item \textbf{Cinta}: Un medio de almacenamiento infinito dividido en celdas, donde cada celda contiene un símbolo de un alfabeto finito.
      \item \textbf{Cabezal de lectura/escritura}: Un dispositivo que puede leer el contenido de una celda, escribir un nuevo símbolo y moverse a la izquierda o derecha.
      \item \textbf{Conjunto de estados}: Una colección finita de estados internos que describen la configuración actual de la máquina.
      \item \textbf{Función de transición}: Un conjunto de reglas que determinan cómo la máquina cambia de estado, escribe en la cinta y mueve el cabezal en función del estado actual y el símbolo leído.
\end{itemize}

\paragraph{Máquina de Turing determinista (\textit{DTM}):}
En una Máquina de Turing determinista, para cada estado y cada símbolo leído, existe como máximo una transición
definida.
\paragraph{Máquina de Turing no determinista (\textit{NTM}):}
En una Máquina de Turing no determinista, para cada estado y símbolo leído, pueden existir múltiples
transiciones posibles.

Una máquina de Turing consiste la definición formal de algoritmo en Ciencias de la Computación y es el eje central para la resolución de problemas.

\subsection{Notación asintótica}

La notación asintótica se utiliza para describir el comportamiento de una función $f(n)$ a medida que $n$ crece hacia el infinito. A continuación se definen las notaciones más comunes:

\begin{itemize}
      \item \textbf{Notación $O(f(n))$}: Una función $g(n)$ pertenece a $O(f(n))$ si existen constantes positivas $c$ y $n_0$ tales que:
            \[
                  g(n) \leq c \cdot f(n) \quad \text{para todo } n \geq n_0.
            \]
            Esta notación proporciona un límite superior asintótico para $g(n)$.

      \item \textbf{Notación $\Omega(f(n))$}: Una función $g(n)$ pertenece a $\Omega(f(n))$ si existen constantes positivas $c$ y $n_0$ tales que:
            \[
                  g(n) \geq c \cdot f(n) \quad \text{para todo } n \geq n_0.
            \]
            Esta notación proporciona un límite inferior asintótico para $g(n)$.

      \item \textbf{Notación $\Theta(f(n))$}: Una función $g(n)$ pertenece a $\Theta(f(n))$ si:
            \[
                  g(n) \in O(f(n)) \quad \text{y} \quad g(n) \in \Omega(f(n)).
            \]
            Es decir, $f(n)$ acota $g(n)$ tanto superior como inferiormente.
\end{itemize}

La notación asintótica permite describir el tiempo de ejecución un algoritmo en cuanto al número de operaciones básicos realizadas
por un modelo formal de cómputo (por ejemplo una máquina de Turing). Algoritmos como determinar el mínimo y el máximo de
un array son $\Theta(n)$, ya que necesitan realizar una cantidad de operaciones de orden $n$ en relación con el tamaño de la entrada.

\subsection{Clases de problemas}

Los problemas computacionales \cite{authomataTheory} se agrupan en diferentes clases según los recursos necesarios para resolverlos.

\paragraph{Problemas en la clase P:}
Un problema pertenece a la clase P si puede resolverse en tiempo polinomial mediante una Máquina de Turing determinista. Es decir, existe un algoritmo determinista que, para una entrada de tamaño $n$, produce la solución en tiempo $O(n^k)$ para alguna constante $k$.

\paragraph{Problemas en la clase NP:}
Un problema pertenece a NP si su solución puede verificarse en tiempo polinomial mediante una Máquina de Turing determinista. Alternativamente, un problema está en NP si puede resolverse en tiempo polinomial mediante una Máquina de Turing no determinista.

\paragraph{Problemas en la clase NP-Completo:}
Un problema pertenece a la clase NP-Completo, si pertenece a NP y además es tan difícil como cualquier otro problema en NP. Esto significa que cualquier problema en NP puede reducirse a este problema en tiempo polinómico.

\paragraph{Problemas no decidibles:}
Un problema es no decidible si no existe una Máquina de Turing que pueda resolverlo correctamente para todas las entradas posibles. Esto significa que no hay algoritmo que garantice una respuesta en tiempo finito en todos los casos. Un ejemplo clásico de problema no decidible es el \textit{Problema de la Parada}, que consiste en determinar si una Máquina de Turing se detendrá para una entrada dada.
\subsection{P vs NP}

La relación entre las clases P y NP es uno de los problemas abiertos más importantes en la teoría de la
computación. Hasta la fecha, se desconoce si $\text{P} = \text{NP}$ o si $\text{P} \neq \text{NP}$. Por otro
lado el conjunto de problemas NP-Completo brinda una base sólida para el problema anterior, ya que dada su
definición cualquier problema perteneciente a este conjunto que sea soluble en tiempo polinomial
implica que todos los problemas en NP lo son. Además, existen problemas que no están en P ni en NP, como
los problemas indecidibles.

\section{Mecanismos de escritura regulada}

\subsection{Autómata regular}

Un autómata regular \cite{authomataTheory}, también conocido como autómata finito, es un modelo matemático para reconocer lenguajes regulares. Este tipo de autómata se define como una máquina abstracta que procesa cadenas de símbolos de un alfabeto finito y determina si una cadena pertenece a un lenguaje regular.

Un autómata regular se puede representar como una 5-tupla $$\mathcal{A} = (Q, \Sigma, \delta, q_0, F)$$ donde:

\begin{itemize}
      \item $Q$: Es un conjunto finito de \textbf{estados}.
      \item $\Sigma$: Es el \textbf{alfabeto} finito de entrada.
      \item $\delta$: Es la \textbf{función de transición}, $\delta: Q \times \Sigma \to Q$, que define cómo el autómata cambia de estado en función del símbolo leído.
      \item $q_0 \in Q$: Es el \textbf{estado inicial} desde donde comienza la computación.
      \item $F \subseteq Q$: Es el conjunto de \textbf{estados de aceptación o estados finales}.
\end{itemize}

El autómata comienza en el estado inicial $q_0$ y procesa una cadena de entrada símbolo por símbolo. En cada paso, la función de transición $\delta$ determina el siguiente estado del autómata. Si, después de procesar toda la cadena, el autómata termina en un estado de aceptación $q \in F$, entonces la cadena es aceptada; de lo contrario, es rechazada.

Se puede extender el concepto de autómata finito añadiendo un nuevo tipo de transición que no consume ningún caracter, la cual recibe el nombre de transición $\varepsilon$.
Se puede demostrar que el conjunto de lenguajes reconocido por un autómata finito sin transiciones $\varepsilon$ (\textit{autómata finito determinista}) es equivalente al conjunto de lenguajes reconocidos por un autómata finito con transiciones $\varepsilon$ (\textit{autómata finito no determinista}).

\subsection{Autómata de pila y Gramáticas libres del contexto}

Un autómata de pila \cite{authomataTheory} es un modelo matemático de computación que extiende los autómatas finitos al incluir una estructura de datos adicional: una pila. Este modelo es capaz de reconocer lenguajes libres de contexto,
proporcionando una conexión directa con las gramáticas libres de contexto \textit{CFG}, es decir dada una gramática libre del contexto se puede construir un autómata de pila que reconozca el lenguaje generado por la gramática y viceversa.

Formalmente, un autómata de pila se define como una 7-tupla
\[
      \mathcal{A} = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, F),
\]
donde:

\begin{itemize}
      \item $Q$: Es un conjunto finito de \textbf{estados}.
      \item $\Sigma$: Es el \textbf{alfabeto} finito de entrada.
      \item $\Gamma$: Es el \textbf{alfabeto} finito de la pila (conjunto de símbolos que se pueden almacenar en la pila).
      \item $\delta$: Es la función de transición, $\delta: Q \times (\Sigma \cup \{\varepsilon\}) \times \Gamma \to \mathcal{P}(Q \times \Gamma^*)$, que describe cómo cambia el estado, el contenido de la pila y la posición en la entrada.
      \item $q_0 \in Q$: Es el \textbf{estado inicial} desde donde comienza la computación.
      \item $Z_0 \in \Gamma$: Es el símbolo inicial en la pila.
      \item $F \subseteq Q$: Es el conjunto de \textbf{estados de aceptación o estados finales}.
\end{itemize}

Un autómata de pila procesa una cadena de entrada desde el estado inicial $q_0$ y puede utilizar transiciones $\varepsilon$ (sin consumir entrada). En cada paso, la función $\delta$ determina el nuevo estado, los símbolos que se empujan o desapilan, y el avance en la entrada. Si, tras procesar toda la cadena, el autómata termina en un estado de aceptación o con una pila vacía (dependiendo del criterio de aceptación), la cadena es aceptada.


\subsection{Gramáticas Matriciales}

Una gramática matricial \cite{simpleMatrixLanguages} de grado $n$ \textit{$n$-MG} es una 4-tupla:

\[
      G_n = (V, P, S,\Sigma)
\]

donde:
\begin{itemize}
      \item \( V \) es un conjunto finito de \textbf{símbolos no terminales}.
      \item \( \Sigma \) es un conjunto finito de \textbf{símbolos terminales}, con \( V \cap \Sigma = \emptyset \).
      \item \( P \) es un conjunto finito de matrices. Cada matriz es una secuencia ordenada de \textbf{producciones} de la forma:
            \[
                  [P_1, P_2, \dots, P_k]
            \]
            donde cada \( P_i \) es una regla \( A \to \alpha \), con $1\leq k\leq n$, \( A \in N \) y \( \alpha \in (N \cup T)^* \).
      \item \( S \in V \) es el \textbf{símbolo inicial}.
\end{itemize}

Observe que das CFG son gramáticas matriciales de grado 1, es decir $1-MG$.

\subsubsection{Proceso de derivación}

El proceso de derivación en una gramática matricial se realiza de la siguiente manera:
\begin{enumerate}
      \item Se selecciona una matriz \( [P_1, P_2, \dots, P_k] \in P \).
      \item Las reglas \( P_1, P_2, \dots, P_k \) se aplican de manera secuencial a la cadena actual.
      \item La derivación continúa hasta que la cadena derivada contenga solo símbolos terminales, es decir, pertenezca a \( T^* \).
\end{enumerate}

\subsubsection{Gramáticas Matriciales Simples}

Una gramática matricial simple de grado $n$ \textit{$n$-SMG} es una ($n$+3)-tupla:
$$
      G_n=(V_1,V_2,\ldots,V_n,P,S,\Sigma)
$$
donde:
\begin{itemize}
      \item \( V_1, V_2, \ldots, V_n \) son conjuntos finitos de \textbf{símbolos no terminales} disjuntos 2 a 2.
      \item \( \Sigma \) es un conjunto finito de \textbf{símbolos terminales}, con \( V_i \cap \Sigma = \emptyset\,\forall\,1\leq i\leq n \).
      \item \( P \) es un conjunto finito de matrices. Cada matriz es una secuencia ordenada \textbf{producciones} que cumplan con una de las siguientes reglas:
            \begin{itemize}
                  \item $[S\to w]$, donde $w\in \Sigma ^*$.
                  \item $[S\to a_{11}A_{11}\ldots A_{1k}a_{21}A_{21}\ldots A_{2k}\ldots A_{n1}a_{n1}\ldots A_{nk}b]$,
                        donde $\forall i,j$ con $1\leq i\leq n\wedge 1\leq j\leq k$ se cumple que
                        $A_{ij}\in V_i$, $a_{ij}\in \Sigma ^*$ y $b\in \Sigma ^*$.
                  \item $[A_1\to w_1,\ldots, A_n\to w_n]$, donde $A_i\in V_i\wedge w_i\in \Sigma ^*$ $\forall i\, 1\leq i\leq n$.
                  \item $[A_1 \to a_{11}A_{11}\ldots a_{1k}A_{1k}b_1,\ldots,A_n \to a_{n1}A_{n1}\ldots a_{nk}A_{nk}b_n]$, donde $\forall i,j$
                        con $1\leq i\leq n\wedge 1\leq j\leq k$ se cumple que
                        $A_{ij}\in V_i$, $a_{ij}\in \Sigma ^*$ y $b_{i}\in \Sigma ^*$.
            \end{itemize}
      \item \( S \in V \) es el \textbf{símbolo inicial}.
\end{itemize}


Observe que la restricción impuesta sobre las $n$-MG es cada matriz de producciones debe contener exactamente $n$ reglas de producción
donde cada regla de producción utiliza no terminales de conjuntos distintos o puede contener una única producción cuya secuencia de no terminales
esta compuesta por una secuencia de subsecuentes de terminales de conjuntos distintos.

\subsection{Gramáticas de Índice Global}

\section{Gramáticas de Concatenación de Rango}

Las gramáticas de concatenación de rango (\textit{RCG}) \cite{mainRCGBib} son un formalismo de gramáticas desarrollado para describir lenguajes más generales que los generados por gramáticas libres del contexto.
Este formalismo extiende las capacidades descriptivas al incluir relaciones entre rangos de la cadena de una manera más flexible,
permitiendo la generación de lenguajes sensibles al contexto.

\subsection{Definiciones}

\paragraph{Rango:} un rango es una tupla $(i, j)$ que representa un intervalo de posiciones en la cadena, donde $i$ y $j$ son enteros no negativos tales que $i \leq j$.

\paragraph{Gramática de Concatenación de Rango Positiva:} una gramática de concatenación de rango positiva (\textit{PRCG}) se define como una 5-tupla:

\[
      G = (N, T, V, P, S),
\]
donde:

\begin{itemize}
      \item $N$: Es un conjunto finito de \textbf{predicados o símbolos no terminales}: Cada predicado tiene una \textbf{aridad}, que indica el número de argumentos que toma.
      \item $T$: Es un conjunto finito de \textbf{símbolos terminales}.
      \item $V$: Es un conjunto finito de \textbf{variables}.
      \item $P$: Es un conjunto finito de \textbf{cláusulas}, de la forma:
            \[
                  A(x_1, x_2, \ldots, x_k) \to B_1(y_{1,1}, y_{1,2}, \ldots, y_{1,m_1}) \ldots B_n(y_{n,1}, y_{n,2}, \ldots, y_{n,m_n}),
            \]
            donde $A, B_i \in N$, $x_i, y_{i,j} \in (V \cup T)^*$, y $k$ es la aridad de $A$.
      \item $S \in N$: Es el \textbf{predicado inicial} de la gramática.
\end{itemize}

\paragraph{Gramática de Concatenación de Rango Negativa:} una gramática de concatenación de rango negativa (\textit{NRCG}) es similar a una PRCG, pero predicados o no terminales negativos que se denotan de la siguiente manera: $\overline{A}$.

\paragraph{Gramática de Concatenación de Rango Simple:} las gramáticas de concatenación de rango simple (\textit{SRCG}) son un subconjunto de las RCG que restringen la forma de las cláusulas de producción.
Una RCG $G$ es \textbf{simple} si los argumentos en el lado derecho de una cláusula son variables distintas, y todas estas variables (y no otras) aparecen una sola vez en los argumentos del lado izquierdo.
Un resultado interesante es que para cada CFL existe una SRCG equivalente que genera el mismo lenguaje.

\paragraph{Sustiución de rango:} una sustitución de rango es un mecanismo que reemplaza una variable por un rango de la cadena.
Por ejemplo dado el predicado $A(Xa)$ donde $X \in V \wedge a \in T$, si se instancia la cadena $baa$ en $A$, $X$ puede
ser asociada con el rango $ba$ de la cadena original.

\subsection{Funcionamiento}

La principal idea detrás de las RCG, para realizar una derivación, se basa en encontrar para cada argumento del predicado izquierdo de una cláusula todas las
posibles sustituciones en rango de la cadena, asociar los valores de las variables a los argumentos de los predicados derechos y continuar
el proceso de derivación en los predicados derechos.

Por ejemplo, dada la cláusula $A(X,aYb)\to B(aXb,Y)$ , donde $X$ y $Y$ son símbolos variables y $a$ y $b$
son símbolos terminales, la cadena predicado $A(a,abb)$ deriva como $B(aab,b)$, porque $A(a,abb)$
coincide con $A(X,aYb)$ cuando $ X=a \wedge Y=b$. De forma similar, si existiera una regla

Una secuencia de argumentos son reconocidos por un predicado si existe una secuencia de derivaciones que comienza
en dicho predicado y termina en la cadena vacía, si el predicado es negativo en el caso de las NRCG ocurre lo contrario
la secuencia de argumentos no es reconocida por el predicado. Una RCG reconoce una cadena si dicha cadena es reconocida
por el predicado inicial.

Ejemplo dada la siguiente RCG:

\[
      G = (N, T, V, P, S),
\]
donde:

\begin{itemize}
      \item  N=$\{A,S\}$.
      \item T=$\{a,b,c\}$.
      \item V=$\{X,Y,Z\}$.
      \item El conjunto de cláusulas $P$ es el siguiente:
            $$S(XYZ)\to A(X,Y,Z)$$
            $$A(aX,aY,aZ)\to A(X,Y,Z)$$
            $$A(bX,bY,bZ)\to A(X,Y,Z)$$
            $$A(cX,cY,cZ)\to A(X,Y,Z)$$
            $$A(\varepsilon,\varepsilon,\varepsilon)\to \varepsilon$$
      \item El símbolo inicial es $S$.
\end{itemize}
La cadena $aaabbbccc$ es reconocida por la RCG anterior, ya que se puede derivar de la siguiente manera:
$$S(abcabcabc)\to A(abc,abc,abc)\to A(bc,bc,bc)\to A(c,c,c)\to A(\varepsilon,\varepsilon,\varepsilon)\to \varepsilon$$

De manera general el lenguaje reconocido por la RCG anterior es $L=\{www\,|\,w\in \{a,b,c\}^*\}$.

\subsection{Propiedades de las RCG}

A continuación se describen las principales propiedades de las RCG:
\begin{itemize}
      \item \textbf{Cerradura bajo unión:} Dadas dos RCG $G_1$ y $G_2$, la unión de los lenguajes reconocidos por $G_1$ y $G_2$ es reconocida por una RCG
            $$G=(N_1\cup N_2\cup \{S\},T_1\cup T_2,V_1\cup V_2,P_1\cup P_2\cup \{S(X)\to S_1(X)|S_2(X)\},S)$$
      \item \textbf{Cerradas bajo intersección:} Dadas dos RCG $G_1$ y $G_2$, la intersección de los lenguajes reconocidos por $G_1$ y $G_2$ es reconocida por una RCG
            $$G=(N_1\cup N_2\cup \{S\},T_1\cup T_2,V_1\cup V_2,P_1\cup P_2\cup \{S(X)\to S_1(X)S_2(X)\},S)$$
      \item \textbf{Cerradas bajo complemento:} Dada una RCG $G$, el complemento del lenguaje reconocido por $G$ es reconocido por una RCG
            $$G'=(N\cup \{\overline{S}\},T,V,P\cup \{S'(X)\to \overline{S}(X)\},S')$$
      \item \textbf{Cerradas bajo concatenación:} Dadas dos RCG $G_1$ y $G_2$, la concatenación de los lenguajes reconocidos por $G_1$ y $G_2$ es reconocida por una RCG
            $$G=(N_1\cup N_2\cup \{S\},T_1\cup T_2,V_1\cup V_2,P_1\cup P_2\cup \{S(XY)\to S_1(X)S_2(Y)\},S)$$
      \item \textbf{Cerradas bajo estrella de Kleene:} Dada una RCG $G$, la estrella de Kleene del lenguaje reconocido por $G$ es reconocida por una RCG
            $$G'=(N\cup \{S'\},T,V,P\cup \{S'(XY)\to S(X)S'(Y)|\varepsilon\},S')$$
\end{itemize}


\subsection{Problema de la palabra, problema del vacío y equivalencia de 2 RCG}

\paragraph{Problema de la palabra:} En general en la mayoría de los casos este problema es polinomial y pasa por
un algoritmo de memorización sobre las cadenas que son instanciadas en los rangos de los predicados de la RCG \cite{mainRCGBib} (como la cantidad
máxima de rangos de la cadena es $n^2$ y la máxima aridad de un predicado es constante, este proceso de memorización cuenta
con cantidad polinomial de estados), en
una complejidad de $O(|P|n^{2h(l+1)})$ donde $h$ es la máxima aridad en un predicado, $l$ es la máxima cantidad de predicados
en el lado derecho de una cláusula y $n$ es la longitud de la cadena a ser reconocida.

Pero existen casos en los que el problema de la palabra no
es polinomial, por ejemplo puede pasar que se instancien argumentos de en los predicados con rangos que no pertenezcan
a la propia cadena de entrada y sean generados durante el proceso de reconocimiento.

\paragraph{Problema del vacío:} El problema del vacío para una RCG es indecidible \cite{propertiesRCGBib}, la razón principal para esto es que como se mencionó anteriormente
para toda CFL existe una RCG equivalente y como las RCG son cerradas bajo intersección existen RCG que describen
la intersección de 2 lenguajes libres del contexto y determinar si dicha intersección es vacía es un problema indecidible.

En el caso de las SRCG este problema es polinomial.

\paragraph{Problema de la equivalencia:} El problema de la equivalencia para 2 RCG es indecidible, la demostración es muy sencilla dadas 2 RCG $G_1$ y $G_2$ el problema
de saber si $G_1$ es equivalente a $G_2$ es equivalente a saber si $G_1\cap \overline{G_2}=\emptyset$ y como se mencionó anteriormente el problema del vacío para una RCG
es indecidible.

\section{Problema de la satisfacibilidad booleana}

El problema de la satisfacibilidad booleana (\textit{SAT}), es un problema fundamental en la teoría de la computación y la lógica matemática. El objetivo principal del problema es determinar si existe una asignación de valores a las variables de una expresión booleana tal que la expresión sea verdadera.

\subsection{Variables booleanas}

Una variable booleana es una variable que puede tomar uno de dos valores posibles: \textit{true} (verdadero) o \textit{false} (falso). Estas variables se utilizan para construir expresiones lógicas.

\subsection{Literales}

Un literal es una variable booleana o su negación. Formalmente, si \( x \) es una variable booleana, entonces \( x \) y \( \neg x \) (la negación de \( x \)) son literales. Un literal puede tomar los valores \( true \) o \( false \) dependiendo de la asignación de valores a las variables.

\subsection{Cláusulas}

Una cláusula es una disyunción (operador \textbf{OR}) de uno o más literales. Por ejemplo, la cláusula \( (x \vee \neg y \vee z) \) es una disyunción de tres literales: \( x \), \( \neg y \) y \( z \). Una cláusula es verdadera si al menos uno de sus literales es verdadero. Si todos los literales son falsos, la cláusula será falsa.

\subsection{Fórmulas en forma normal conjuntiva}

Una fórmula booleana en forma normal conjuntiva (\textit{CNF}) es una conjunción (operador \textbf{AND}) de cláusulas. En otras palabras, es una expresión booleana que se puede escribir como una serie de cláusulas unidas por el operador \textbf{AND}. Por ejemplo:

\[
      (x \vee \neg y \vee z) \wedge (\neg x \vee y) \wedge (x \vee \neg z)
\]

\subsection{Fórmulas booleanas equivalentes}

Dos fórmulas booleanas se consideran equivalentes si, para cualquier asignación de valores a sus variables, ambas producen el mismo resultado lógico. Por ejemplo, las fórmulas \( x \vee (y \wedge z) \) y \( (x \vee y) \wedge (x \vee z) \) son equivalentes, ya que para cualquier combinación de valores \( x, y, z \), ambas tienen el mismo valor lógico.

Para cualquier fórmula booleana existe una fórmula booleana equivalente en CNF y el algoritmo para encontrarla es polinomial, por lo tanto
de aquí se puede asumir que toda fórmula booleana está en CNF.

\subsection{Definición del problema de la satisfacibilidad booleana}

El problema de la satisfacibilidad booleana, o SAT, consiste en determinar si existe una asignación de valores \( true \) o \( false \) a las variables de una fórmula booleana tal que la fórmula completa sea verdadera. En términos formales, dado un conjunto de cláusulas en CNF, el problema es encontrar una asignación de valores a las variables que haga que la conjunción de las cláusulas sea verdadera.

Formalmente, se dice que una fórmula booleana en CNF es satisfacible si existe una asignación de valores a las variables tal que todas las cláusulas de la fórmula sean verdaderas simultáneamente.

\begin{itemize}
      \item Si existe tal asignación, la fórmula es \textit{satisfacible}.
      \item Si no existe tal asignación, la fórmula es \textit{insatisfacible}.
\end{itemize}

Un SAT con exactamente $n$ variables distintas se denomina $n$-SAT.

\subsection{SAT como Problema NP-Completo}

El SAT es el primer problema demostrado como NP-Completo \cite{authomataTheory} y juega un rol central en la teoría de la complejidad computacional. Se define en la clase NP porque, dada una asignación de valores a las variables de la fórmula booleana, se puede verificar en tiempo polinómico si dicha asignación satisface la fórmula.

Además, la prueba de que SAT es NP-Completo fue una de las contribuciones principales de Stephen Cook en 1971, marcando el inicio de la teoría de la NP-completitud.

\subsection{Equivalencia entre SAT y 3-SAT}

Para el problema 2-SAT existe una solución polinomial que determina si la fórmula booleana es satisfacible o no, pero para el problema 3-SAT no se conoce ningún algoritmo que permita
determinar si una fórmula booleana es satisfacible o no.

Cualquier fórmula booleana del problema $n$-SAT puede ser reducida a una fórmula booleana equivalente del problema 3-SAT, por lo tanto, SAT es equivalente a 3-SAT en términos de complejidad computacional.

\paragraph{Transformación de SAT a 3-SAT:}

Dada una fórmula en CNF con cláusulas de \( k > 3 \) literales, se puede convertir a 3-CNF introduciendo variables adicionales. Por ejemplo, considere una cláusula de cuatro literales:

\[
      (a \vee b \vee c \vee d)
\]

Esta cláusula puede reescribirse como un conjunto de cláusulas en 3-CNF introduciendo una nueva variable \( x \):

\[
      (a \vee b \vee x) \wedge (\neg x \vee c \vee d)
\]

Este proceso se puede aplicar iterativamente para todas las cláusulas con más de tres literales, asegurando que la nueva fórmula sea satisfacible si y solo si la fórmula original también lo es.

\subsection{Problemas SAT solubles en tiempo polinomial}

Como se mencionó anteriormente no se conoce ningún algoritmo polinomial para resolver el problema SAT en general, pero
existen casos particulares del problema que sí pueden ser resueltos en tiempo polinomial. A continuación se presentan los
principales casos:

\begin{enumerate}
      \item \textbf{1-SAT:} El problema 1-SAT es una instancia particular de SAT donde cada cláusula tiene a lo sumo un literal.
            Este problema puede ser resuelto en tiempo polinomial mediante un algoritmo de asignación de valores de verdad.
      \item \textbf{2-SAT:} Como se mencionó anteriormente, el problema 2-SAT puede ser resuelto en tiempo polinomial mediante
            una modelación basada en grafos.
      \item \textbf{Horn-SAT:} El problema Horn-SAT es una generalización del problema 2-SAT, donde cada cláusula tiene a lo sumo
            un literal positivo. Este problema puede ser resuelto en tiempo polinomial mediante el algoritmo de resolución de Horn.
\end{enumerate}

\begin{thebibliography}{9}

      \bibitem{authomataTheory}
      John E. Hopcroft, Rajeev Motwani, Jeffrey D. Ullman.
      \textit{Introduction to Automata Theory, Languages, and Computation}.
      Addison-Wesley,

      \bibitem{simpleMatrixLanguages}
      Oscar H. Ibarra.
      \textit{Simple Matrix Languages}

      \bibitem{mainRCGBib}
      Pierre Boullier.
      \textit{Proposal for a Natural Language Processing Syntactic Backbone},
      1998.

      \bibitem{propertiesRCGBib}
      Pierre Boullier.
      \textit{A Cubic Time Extension of Context-Free Grammars},
      1999.
\end{thebibliography}

\end{document}