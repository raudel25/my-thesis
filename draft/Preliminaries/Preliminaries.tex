\documentclass[12pt]{article}

\usepackage[utf8]{inputenc} % Permite escribir caracteres especiales directamente
\usepackage[spanish]{babel} % Configura el idioma a español

\usepackage{amsmath}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage[lmargin=2cm,rmargin=5cm]{geometry}

\input{word-comments.tex}


\parskip=5pt

\title{Preliminares}
\author{Raudel Alejandro Gómez Molina}

\begin{document}

\maketitle

\section{Teoría de Lenguajes}

En esta sección se definen los principales conceptos de teoría de lenguajes que sirven de base al contenido de las secciones posteriores.

\subsection{Conceptos básicos}

\paragraph{Alfabeto:} Un alfabeto, denotado como $\Sigma$, es un conjunto finito y no vacío de símbolos.

Por ejemplo, el alfabeto $\Sigma=\{1,0\}$ está formado por los símbolos 0 y 1.

\paragraph{Cadena:} Una cadena es una sucesión finita de símbolos del alfabeto.

Por ejemplo: $11$ y $101$ pueden ser cadenas sobre el alfabeto $\Sigma$.

\paragraph{Lenguaje:} Un lenguaje es un conjunto de cadenas definido sobre un alfabeto.

Por ejemplo: el lenguaje de la
representación binaria de todos los números pares $L=\{w\,|\,\text{last}(w)=0\}$, $\text{last}(w)$
representa el último caracter de la cadena $w$.

Dados los conceptos básicos, ahora es necesario definir las operaciones básicas entre los elementos de la teoría de lenguajes.

\subsection{Operaciones con Lenguajes}

Como los lenguajes son conjuntos, todas las operaciones sobre conjuntos también se definen para lenguajes.

\paragraph{Unión:} La unión de dos lenguajes $L_1$ y $L_2$ se define como el conjunto de cadenas que
pertenecen a $L_1$ o a $L_2$:
$$L_1\cup L_2=\{w\,|\,w\in L_1\,\vee\,w\in L_2\}.$$

\paragraph{Intersección:} La intersección de dos lenguajes $L_1$ y $L_2$ se define como el conjunto de
cadenas que pertenecen a $L_1$ y a $L_2$:
$$L_1\cap L_2=\{w\,|\,w\in L_1\,\wedge\,w\in L_2\}.$$

\paragraph{Concatenación:} La concatenación de dos lenguajes $L_1$ y $L_2$ se define como el conjunto
de cadenas que resultan de concatenar una cadena de $L_1$ con una cadena de $L_2$:
$$L_1\circ L_2=\{w_1w_2\,|\,w_1\in L_1\,\wedge\,w_2\in L_2\}.$$
\paragraph{Complemento:} El complemento de un lenguaje $L$ se define como el conjunto de cadenas que no
pertenecen a $L$:
$$\overline{L}=\{w\,|\,w\notin L\}.$$
\paragraph{Clausura de Kleene:} La clausura de Kleene de un lenguaje $L$ se define como el conjunto de
cadenas que resultan de concatenar cero o más cadenas de $L$:
$$L^*=\{w_1w_2\ldots w_n\,|\,n\geq 0\,\text{y}\,w_i\in L\}$$

\paragraph{Homorfismo:} Dados un alfabeto \( \Sigma \) y un alfabeto \( \Gamma \), un homomorfismo es una función:
\[
      h: \Sigma^* \to \Gamma^*
\]
tal que:
\begin{enumerate}
      \item Para cada \( a \in \Sigma \), \( h(a) \) es una cadena en \( \Gamma^* \).
      \item Para cualquier par de cadenas \( u, v \in \Sigma^* \), se cumple que:
            \[
                  h(uv) = h(u) h(v),
            \]
            es decir, el homomorfismo preserva la concatenación.
\end{enumerate}

Por ejemplo sobre el alfabeto $\Sigma=\{a,b\}$, se define el homomorfismo $h$, tal que $h(a)=0$ y $h(b)=1$, entonces
$h(ab)=01$.

Todos los conceptos anteriormente planteados definen la base de la teoría de lenguajes y de estos se derivan algunas 
preguntas como determinar si una cadena pertenece a un lenguaje o determinar si un lenguaje es vacío. A continuación se presentan 3 problemas que serán usados en el desarrollo de este trabajo.

\subsection{Problemas relacionados con Lenguajes}

Los problemas relacionados con la teoría de lenguajes permiten vincular los problemas de otra naturaleza 
con su representación en la teoría de lenguajes formales. 

\paragraph{Problema de la palabra:} Consiste en determinar si una cadena pertenece a un lenguaje dado.

Todo problema en Ciencia de la Computación puede ser reducido a un problema de la palabra, ya que cualquier problema
puede ser codificado como un lenguaje formal \cite{authomataTheory}.

\paragraph{Problema del vacío:} Consiste en determinar si un lenguaje es vacío. 

\paragraph{Problema de la equivalencia:} Consiste en determinar si dos $L_1$ y $L_2$ lenguajes son iguales (es decir si se cumple que
$L_1\subseteq L_2 \wedge L_2\subseteq L_1$).

En la próxima sección se presentan las gramáticas, un mecanismo que permite definir un lenguaje.

\subsection{Gramáticas}

Una \textbf{gramática} es un formalismo utilizado para describir lenguajes formales. Se define como una 4-tupla:
\[
      G = (N, \Sigma, P, S),
\]
donde:
\begin{itemize}
      \item \(N\): Es un conjunto finito de \textbf{símbolos no terminales}, que representan variables o categorías intermedias.
      \item \(\Sigma\): Es un conjunto finito de \textbf{símbolos terminales}, que constituyen el alfabeto del lenguaje. Se cumple que \(N \cap \Sigma = \emptyset\).
      \item \(P\): Es un conjunto finito de \textbf{reglas de producción}, cada una de la forma:
            \[
                  \alpha \to \beta, \quad \text{donde } \alpha \in (N \cup \Sigma)^* \wedge \beta \in (N \cup \Sigma)^*.
            \]
      \item \(S\): Es el \textbf{símbolo inicial}, \(S \in N\), que define el punto de partida para derivar cadenas del lenguaje.
\end{itemize}

Una derivación en la gramática consiste en seleccionar una \textbf{regla de producción} $\alpha \to \beta$ y sustituir una ocurrencia de 
$\alpha$ en una cadena $w$ por $\beta$.

Una cadena $w$, $w\in\Sigma^*$,  se puede generar por la gramática $G$ si existe una secuencia de derivaciones que comienza con $S$
y termina con la cadena $w$.

El lenguaje generado por una gramática \(G\) se denota como:
\[
      L(G) = \{ w \in \Sigma^* \mid S \overset{*}{\to} w \},
\]
donde \(\overset{*}{\to}\) indica una derivación en cero o más pasos.

A continuación se presenta la jerarquía de Chomsky, que clasifica a los lenguajes formales de acuerdo con su poder de generación.

\subsection{Jerarquía de Chomsky}

La \textbf{Jerarquía de Chomsky} (Figura~\ref{fig:ChomskySchema}) clasifica las gramáticas en cuatro tipos, según las restricciones en sus reglas de producción y la capacidad expresiva de los lenguajes que generan \cite{geeksforgeeks_chomsky_hierarchy}.

\begin{enumerate}
      \item \textbf{Tipo 0: Gramáticas irrestrictas}
            \begin{itemize}
                  \item No tienen restricciones en las reglas de producción.
                  \item Cada regla tiene la forma: \(\alpha \to \beta\), donde \(\alpha, \beta \in (N \cup \Sigma)^*\) y \(\alpha \neq \varepsilon\).
                  \item Todo lenguaje generado por una gramática irrestricta se denomina \textbf{lenguaje recursivamente enumerable}.
            \end{itemize}
            
      \item \textbf{Tipo 1: Gramáticas dependientes del contexto}
            \begin{itemize}
                  \item Cada regla tiene la forma: \(\alpha A \gamma \to \alpha \beta \gamma\), donde \(A \in N\), \(\alpha, \beta, \gamma \in (N \cup \Sigma)^*\), y \(|\beta| \geq 1\).
                  \item Todo lenguaje generado por una gramática dependiente del contexto se denomina \textbf{lenguaje dependiente del contexto}.
                  \item Todo lenguaje dependiente del contexto es también un lenguaje recursivamente enumerable.
            \end{itemize}
            
      \item \textbf{Tipo 2: Gramáticas libres del contexto}
            \begin{itemize}
                  \item Cada regla tiene la forma: \(A \to \beta\), donde \(A \in N\) y \(\beta \in (N \cup \Sigma)^*\).
                  \item Todo lenguaje generado por una gramática libre del contexto se denomina \textbf{lenguaje libre del contexto}.
                  \item Todo lenguaje libre del contexto es también un lenguaje dependiente del contexto.
            \end{itemize}
            
      \item \textbf{Tipo 3: Gramáticas regulares}
            \begin{itemize}
                  \item Las reglas tienen la forma:
                        \[
                              A \to aB \quad \text{o} \quad A \to a,
                        \]
                        donde \(A, B \in N\) y \(a \in \Sigma\).
                  \item Todo lenguaje generado por una gramática regular se denomina \textbf{lenguaje regular}.
                  \item Todo lenguaje regular es un lenguaje libre del contexto.
            \end{itemize}
\end{enumerate}


\begin{figure}
      \centering
      \begin{tikzpicture}[scale=1]
            \draw[thick, fill=red!20] (0,0) ellipse (4cm and 2cm);
            \node at (0,1.7) {\textbf{\textcolor{red!70!black}{Tipo 0}}};
            
            \draw[thick, fill=blue!20] (0,0) ellipse (3cm and 1.5cm);
            \node at (0,1.2) {\textbf{\textcolor{blue!70!black}{Tipo 1}}};
            
            \draw[thick, fill=green!20] (0,0) ellipse (2cm and 1cm);
            \node at (0,0.7) {\textbf{\textcolor{green!70!black}{Tipo 2}}};
            
            \draw[thick, fill=yellow!20] (0,0) ellipse (1cm and 0.5cm);
            \node at (0,0) {\textbf{\textcolor{yellow!70!black}{Tipo 3}}};
      \end{tikzpicture}
      \caption{Esquema de la Jerarquía de Chomsky}
      \label{fig:ChomskySchema} %
\end{figure}

Las diferencias entre los elementos de la Jerarquía de Chomsky se pueden ilustrar con el lenguaje 
\textit{Copy} sobre un alfabeto $\Sigma$, que se define como $L_{copy}=\{w^+\,|\,w\in Z^*\}$.
Si se toma un caso particular de $L_{copy}$, al cual se le llama $L_{copy}^n=\{w^n\,|\,w\in Z^*\}$,
$L_{copy}^1$ es un lenguaje regular, mientras que $L_{copy}^2$ es un lenguaje libre del contexto y por último
$L_{copy}^k\,\forall\,k\geq 3$ es un lenguaje dependiente del contexto \cite{authomataTheory}. El lenguaje 
$L_{copy}$ se usa en los restantes capítulos como base de formalismos que describen el tema analizado en este trabajo.

En la próxima sección se presentan los principales conceptos relacionados con las gramáticas libres del contexto y las 
gramáticas regulares. Estos contenidos sirven de base para el resto de los capítulos y secciones.
\section{Autómatas}
Un autómata es un modelo de cómputo en la teoría de lenguajes. En esta sección se abordan los principales conceptos sobre los autómatas.
\subsection{Autómata regular}

Un autómata regular \cite{authomataTheory}, también conocido como autómata finito, es un modelo matemático 
que permite reconocer lenguajes regulares. Este tipo de autómata se define como una máquina abstracta que 
procesa cadenas de símbolos de un alfabeto finito y determina si una cadena pertenece a un lenguaje regular.

Un autómata regular se define como una 5-tupla $$\mathcal{A} = (Q, \Sigma, \delta, q_0, F),$$ donde:

\begin{itemize}
      \item $Q$: Es un conjunto finito de \textbf{estados}.
      \item $\Sigma$: Es el \textbf{alfabeto} finito de entrada.
      \item $\delta$: Es la \textbf{función de transición}, $\delta: Q \times \Sigma \to Q$, que define cómo el autómata cambia de estado en función del símbolo leído.
      \item $q_0 \in Q$: Es el \textbf{estado inicial} desde donde comienza la computación.
      \item $F \subseteq Q$: Es el conjunto de \textbf{estados de aceptación o estados finales}.
\end{itemize}

El autómata comienza en el estado inicial $q_0$ y procesa una cadena de entrada símbolo por símbolo.
En cada paso, la función de transición $\delta$ determina el siguiente estado del autómata. Si, después de
procesar toda la cadena, el autómata termina en un estado de aceptación $q \in F$, entonces la cadena
se acepta; de lo contrario, se rechaza.

Se puede extender el concepto de autómata finito añadiendo un nuevo tipo de transición que no consume ningún 
caracter, la cual recibe el nombre de transición $\varepsilon$. Se puede demostrar \cite{authomataTheory} que
el conjunto de lenguajes reconocido por un autómata finito sin transiciones $\varepsilon$
(\textit{autómata finito determinista}) es equivalente al conjunto de lenguajes reconocido por un autómata finito con transiciones $\varepsilon$ (\textit{autómata finito no determinista}).

A continuación se presenta el concepto de autómata que reconoce a los lenguajes libres del contexto.
\subsection{Autómata de pila y Gramáticas libres del contexto}

Un autómata de pila \cite{authomataTheory} es un modelo matemático de computación que extiende los autómatas finitos al incluir una estructura de datos adicional: una pila. Este modelo es capaz de reconocer lenguajes libres de contexto,
proporcionando una conexión directa con las gramáticas libres de contexto \textit{CFG}. 
Es decir dada una gramática libre del contexto se puede construir un autómata de pila que reconozca el lenguaje 
generado por la gramática y viceversa \cite{authomataTheory}.

Un autómata de pila se define como una 7-tupla
\[
      \mathcal{A} = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, F),
\]
donde:

\begin{itemize}
      \item $Q$: Es un conjunto finito de \textbf{estados}.
      \item $\Sigma$: Es el \textbf{alfabeto} finito de entrada.
      \item $\Gamma$: Es el \textbf{alfabeto} finito de la pila (conjunto de símbolos que se pueden almacenar en la pila).
      \item $\delta$: Es la función de transición, $\delta: Q \times (\Sigma \cup \{\varepsilon\}) \times \Gamma \to \mathcal{P}(Q \times \Gamma^*)$, que describe cómo cambia el estado, el contenido de la pila y la posición en la entrada.
      \item $q_0 \in Q$: Es el \textbf{estado inicial} desde donde comienza la computación.
      \item $Z_0 \in \Gamma$: Es el símbolo inicial en la pila.
      \item $F \subseteq Q$: Es el conjunto de \textbf{estados de aceptación o estados finales}.
\end{itemize}

Un autómata de pila procesa una cadena de entrada desde el estado inicial $q_0$ y
puede utilizar transiciones $\varepsilon$ (sin consumir entrada). En cada paso, la función $\delta$
determina el nuevo estado, los símbolos que se insertan o sacan de la pila, y el avance en la entrada.
Tras procesar toda la cadena, el autómata termina en un estado de aceptación o con una pila vacía 
(dependiendo del criterio de aceptación), la cadena se acepta.

A continuación se presenta una combinación de un autómata finito con un homomorfismo. 
\subsection{Transductor finito}

Un transductor finito \cite{geeksforgeeks_finite_state_transducer} es un modelo computacional que extiende los autómatas finitos al incluir tanto entradas como salidas.
Formalmente, un transductor finito es un autómata finito con una función de transición extendida
que asocia una salida a cada transición.

Un transductor finito puede representarse como una 6-tupla:
\[
      T = (Q, \Sigma, \Gamma, \delta, q_0, F),
\]
donde:
\begin{itemize}
      \item \(Q\) es el conjunto finito de estados.
      \item \(\Sigma\) es el alfabeto de entrada.
      \item \(\Gamma\) es el alfabeto de salida.
      \item \(\delta: Q \times \Sigma \to Q \times \Gamma^*\) es la función de transición, que mapea una combinación de estado actual y símbolo de entrada a un nuevo estado y una salida.
      \item \(q_0 \in Q\) es el estado inicial.
      \item \(F \subseteq Q\) es el conjunto de estados finales.
\end{itemize}

Observe que un homorfismo es un transductor finito de un solo estado y tantas transiciones hacia el mismo estado como transformaciones
de símbolos en el homomorfismo.

Por ejemplo se define el siguiente transductor finito $T$:
\[
      T = (\{q_0, q_1\}, \Sigma, \Gamma, \delta, q_0, Q),
\]

donde:

\begin{itemize}
      \item \(Q = \{q_0, q_1, q_2\}\) es el conjunto de estados.
      \item \(\Sigma = \{a, b\}\) es el alfabeto de entrada.
      \item \(\Gamma = \{0, 1\}\) es el alfabeto de salida.
      \item \(\delta\) es la función de transición definida por:
            \[
                  \begin{array}{c|c|c}
                        \delta & a        & b        \\
                        \hline
                        q_0    & (q_0, 0) & (q_1, 1) \\
                        q_1    & (q_2, 0) & (q_1, 1) \\
                        q_2    & (q_2, 0) & (q_2, 1) \\
                  \end{array}
            \]
      \item \(q_0\) es el estado inicial.
      \item \(F = \{q_1\}\) es el conjunto de estados finales.
\end{itemize}

Entonces la cadena $aaaabbbbb$ es reconocida por $T$ y $T(aaaabbbbb)=000011111$.

A continuación se describe el modelo de cómputo más general que describe el resto de los elementos de la Jerarquía de Chomsky.

\section{Máquina de Turing}

Una Máquina de Turing \cite{authomataTheory} es un modelo abstracto de computación universal introducido por Alan Turing en 1936. Este modelo consiste en los siguientes componentes:

\begin{itemize}
      \item \textbf{Cinta}: Un medio de almacenamiento infinito dividido en celdas, donde cada celda contiene un símbolo de un alfabeto finito.
      \item \textbf{Cabezal de lectura/escritura}: Un dispositivo que puede leer el contenido de una celda, escribir un nuevo símbolo y moverse a la izquierda o derecha.
      \item \textbf{Conjunto de estados}: Una colección finita de estados internos que describen la configuración actual de la máquina.
      \item \textbf{Función de transición}: Un conjunto de reglas que determinan cómo la máquina cambia de estado, escribe en la cinta y mueve el cabezal en función del estado actual y el símbolo leído.
\end{itemize}

\paragraph{Máquina de Turing determinista (\textit{DTM}):}
En una Máquina de Turing determinista, para cada estado y cada símbolo leído, existe como máximo una transición
definida.
\paragraph{Máquina de Turing no determinista (\textit{NTM}):}
En una Máquina de Turing no determinista, para cada estado y símbolo leído, pueden existir múltiples
transiciones posibles.

La Máquina de Turing es fundamental en el estudio de la computabilidad, ya que establece un marco teórico 
para definir qué problemas son resolubles mediante algoritmos. Este modelo formalizó el concepto de 
\textit{función computable}, es decir, aquellas funciones que pueden ser calculadas mediante una secuencia 
finita de pasos definidos por una máquina de Turing \cite{authomataTheory}.

Todas las operaciones con lenguajes y los problemas relacionados con ellos tienen una dificultad y para medir esta dificultad
se utiliza un marco teórico llamado complejidad computacional, el cual se presenta en la próxima sección.

\section{Complejidad computacional}

En esta sección se definen los principales conceptos de complejidad computacional y las clases de problemas.

A continuación se presenta una notación para describir el tiempo que demora un algoritmo en realizar determinado cómputo.

\subsection{Notación asintótica}

La notación asintótica se utiliza para describir el comportamiento de una función $f(n)$ a medida que $n$ crece hacia el infinito. A continuación se definen las notaciones más comunes:

\begin{itemize}
      \item \textbf{Notación $O(f(n))$}: Una función $g(n)$ pertenece a $O(f(n))$ si existen constantes positivas $c$ y $n_0$ tales que:
            \[
                  g(n) \leq c \cdot f(n) \quad \text{para todo } n \geq n_0.
            \]
            Esta notación proporciona un límite superior asintótico para $g(n)$.
            
      \item \textbf{Notación $\Omega(f(n))$}: Una función $g(n)$ pertenece a $\Omega(f(n))$ si existen constantes positivas $c$ y $n_0$ tales que:
            \[
                  g(n) \geq c \cdot f(n) \quad \text{para todo } n \geq n_0.
            \]
            Esta notación proporciona un límite inferior asintótico para $g(n)$.
            
      \item \textbf{Notación $\Theta(f(n))$}: Una función $g(n)$ pertenece a $\Theta(f(n))$ si:
            \[
                  g(n) \in O(f(n)) \quad \text{y} \quad g(n) \in \Omega(f(n)).
            \]
            Es decir, $f(n)$ acota a $g(n)$ tanto superior como inferiormente.
\end{itemize}

La notación asintótica permite describir el tiempo de ejecución un algoritmo con respecto al número de operaciones 
básicas realizadas por un modelo formal de cómputo (por ejemplo una máquina de Turing). Algoritmos como determinar el mínimo y el máximo de
un arreglo son $\Theta(n)$, ya que necesitan realizar una cantidad $n$ de operaciones básicas en relación con
la cantidad de elementos del arreglo.

Se dice que un algoritmo tiene un tiempo polinomial si puede resolverse en una complejidad de $O(n^k)$, donde $n$ es el tamaño de la entrada del algoritmo y $k$
es una constante. Por ejemplo encontrar el mínimo y el máximo de un arreglo tiene un tiempo polinomial.


En la próxima sección se presenta la clasificación de los problemas de acuerdo a su complejidad computacional.
\subsection{Clases de problemas}

Los problemas computacionales \cite{authomataTheory} se agrupan en diferentes clases según los recursos necesarios para resolverlos.

\paragraph{Problemas en la clase P:}
Un problema pertenece a la clase P si puede resolverse en tiempo polinomial.

\paragraph{Problemas en la clase NP:}
Un problema pertenece a NP si su solución puede verificarse en tiempo polinomial mediante una Máquina de Turing 
determinista. Alternativamente, un problema está en NP si puede resolverse en tiempo polinomial mediante una 
Máquina de Turing no determinista \cite{authomataTheory}.

\paragraph{Problemas en la clase NP-Completo:}
Un problema pertenece a la clase NP-Completo, si pertenece a NP y además es tan difícil como cualquier 
otro problema en NP. Esto significa que cualquier problema en NP puede reducirse a este problema en 
tiempo polinómico \cite{authomataTheory}.

\paragraph{Problemas en la clase NP-Duro:}
Un problema pertenece a la clase NP-Duro, es tan difícil como cualquier otro problema en NP, pero no 
necesariamente pertenece a NP \cite{authomataTheory}.  

\paragraph{Problemas no decidibles:}
Un problema es no decidible si no existe una Máquina de Turing que pueda resolverlo correctamente para todas las 
entradas posibles. Esto significa que no hay algoritmo que garantice una respuesta en tiempo finito en todos los 
casos \cite{authomataTheory}. Un ejemplo clásico de problema no decidible es el \textit{Problema de la Parada}
\cite{authomataTheory}, que consiste en determinar si una Máquina de Turing se detendrá para una entrada dada.

En la siguiente sección se realiza la comparación entre las clases P y NP.

\subsection{P vs NP}

La relación entre las clases P y NP es uno de los problemas abiertos más importantes en la teoría de la
computación \cite{authomataTheory}. Hasta la fecha, se desconoce si $\text{P} = \text{NP}$ o si $\text{P} \neq \text{NP}$,
es decir no se conoce si realmente los problemas en NP son más difíciles que los problemas en P. Por otro
lado el conjunto de problemas NP-Completo brinda una base sólida para el problema anterior, ya que dada su
definición, cualquier problema perteneciente a este conjunto que sea soluble en tiempo polinomial
implica que todos los problemas en NP lo son. Mientras que los problemas en NP-Duro pueden resultar aún más
difíciles, es decir aunque resultara que $\text{P} = \text{NP}$ no se puede asegurar que no existan problemas
en NP-Duro que no se puedan resolver en tiempo polinomial \cite{authomataTheory}.

Por otra parte existen problemas para los cuales no existe ningún algoritmo, como los problemas indecidibles.

A continuación se presenta el problema que sirve de base a los problemas de la clase NP-Completo y que a su
vez, la relación de este con la teoría de lenguajes, es el foco de atención de este trabajo.

\section{Problema de la satisfacibilidad booleana}

El problema de la satisfacibilidad booleana (\textit{SAT}), es un problema fundamental en la teoría de la 
computación y la lógica matemática \cite{authomataTheory}. El objetivo principal del problema es determinar si existe una asignación de valores a las variables de una expresión booleana tal que la expresión sea verdadera.

En las próximas secciones se definen los principales elementos del SAT.
\subsection{Variables booleanas}

Una variable booleana es una variable que puede tomar uno de dos valores posibles: \textit{true} (verdadero) o \textit{false} (falso). Estas variables se utilizan para construir expresiones lógicas.

\subsection{Literales}

Un literal es una variable booleana o su negación. Formalmente, si \( x \) es una variable booleana, entonces \( x \) y \( \neg x \) (la negación de \( x \)) son literales. Un literal puede tomar los valores \( true \) o \( false \) dependiendo de la asignación de valores a las variables.

\subsection{Cláusulas}

Una cláusula es una disyunción (operador \textbf{OR}) de uno o más literales. Por ejemplo, la cláusula \( (x \vee \neg y \vee z) \) es una disyunción de tres literales: \( x \), \( \neg y \) y \( z \). Una cláusula es verdadera si al menos uno de sus literales es verdadero. Si todos los literales son falsos, la cláusula será falsa.

\subsection{Fórmulas en forma normal conjuntiva}

Una fórmula booleana en forma normal conjuntiva (\textit{CNF}) es una conjunción (operador \textbf{AND}) de cláusulas. En otras palabras, es una expresión booleana que se puede escribir como una serie de cláusulas unidas por el operador \textbf{AND}. Por ejemplo:

\[
      (x \vee \neg y \vee z) \wedge (\neg x \vee y) \wedge (x \vee \neg z)
\]

\subsection{Fórmulas booleanas equivalentes}

Dos fórmulas booleanas se consideran equivalentes si, para cualquier asignación de valores a sus variables, ambas producen el mismo resultado lógico. Por ejemplo, las fórmulas \( x \vee (y \wedge z) \) y \( (x \vee y) \wedge (x \vee z) \) son equivalentes, ya que para cualquier combinación de valores \( x, y, z \), ambas tienen el mismo valor lógico.

Para cualquier fórmula booleana existe una fórmula booleana equivalente en CNF \cite{authomataTheory} y 
el algoritmo para encontrarla es polinomial, por lo tanto se puede asumir que toda fórmula booleana está en CNF.

\subsection{Definición del problema de la satisfacibilidad booleana}

El problema de la satisfacibilidad booleana, o SAT, consiste en determinar si existe una asignación de valores \( true \) o \( false \) a las variables de una fórmula booleana tal que la fórmula completa sea verdadera. En términos formales, dado un conjunto de cláusulas en CNF, el problema es encontrar una asignación de valores a las variables que haga que la conjunción de las cláusulas sea verdadera.

Formalmente, se dice que una fórmula booleana en CNF es satisfacible si existe una asignación de valores a las variables tal que todas las cláusulas de la fórmula sean verdaderas simultáneamente.

\begin{itemize}
      \item Si existe tal asignación, la fórmula es \textit{satisfacible}.
      \item Si no existe tal asignación, la fórmula es \textit{insatisfacible}.
\end{itemize}

Un SAT con exactamente $n$ variables distintas en cada cláusula se denomina $n$-SAT.
\subsection{SAT como Problema NP-Completo}

El SAT es el primer problema demostrado como NP-Completo \cite{authomataTheory} y juega un rol central en la teoría de la complejidad computacional. Se define en la clase NP porque, dada una asignación de valores a las variables de la fórmula booleana, se puede verificar en tiempo polinómico si dicha asignación satisface la fórmula.

Además, la prueba de que SAT es NP-Completo fue una de las contribuciones principales de Stephen Cook en 1971 \cite{authomataTheory}, marcando el inicio de la teoría de la NP-completitud.

\subsection{Equivalencia entre SAT y 3-SAT}

Para el problema 2-SAT existe una solución polinomial que determina si la fórmula booleana es satisfacible o no \cite{geeksforgeeks_2sat}, pero para el problema 3-SAT no se conoce ningún algoritmo polinomial que permita
determinar si una fórmula booleana es satisfacible o no \cite{authomataTheory}.

Cualquier fórmula booleana del problema $n$-SAT se puede reducir a una fórmula booleana equivalente del problema 3-SAT, 
por lo tanto, SAT es equivalente a 3-SAT en términos de complejidad computacional \cite{authomataTheory}.

\subsection{Problemas SAT solubles en tiempo polinomial}

Como se mencionó anteriormente no se conoce ningún algoritmo polinomial para resolver el problema SAT en general, pero
existen casos particulares del problema que sí pueden ser resueltos en tiempo polinomial. A continuación se presentan los
principales casos:

\begin{itemize}
      \item \textbf{1-SAT:} El problema 1-SAT es una instancia particular de SAT donde cada cláusula tiene a lo sumo un literal.
            Este problema puede ser resuelto en tiempo polinomial mediante un algoritmo de asignación de valores de booleanos.
            
      \item \textbf{2-SAT:} El problema 2-SAT es una instancia de SAT donde cada cláusula contiene exactamente dos literales.
            Este problema puede ser resuelto en tiempo polinomial mediante una modelación basada en grafos, 
            utilizando algoritmos como la detección de componentes fuertemente conexas en el grafo de implicación.
            
      \item \textbf{Horn-SAT:} El problema Horn-SAT es una generalización del problema SAT,
            donde cada cláusula tiene a lo sumo un literal positivo. 
            Este problema puede ser resuelto en tiempo polinomial mediante el algoritmo de resolución de Horn.
            
      \item \textbf{XOR-SAT:} El problema XOR-SAT es una instancia de SAT donde cada cláusula representa una operación XOR
            sobre los literales. Puede ser resuelto en tiempo polinomial transformando el problema en un sistema de ecuaciones 
            lineales modulares y aplicando eliminación de Gauss.
\end{itemize}



\notaparaelautor{Debe haber dos o tres más por ahí, que se hayan publicado, aunque sean muy específicos para situaciones específicas.}

En este capítulo se abordó todo el contenido de la teoría de lenguajes y el SAT necesario para el contenido de los capítulos posteriores.
En el siguiente capítulo se abordan los formalismos de escritura regulada que se usan en los capítulos 3, 4 y 5, estos formalismos reconocen lenguajes
que pertenecen a los lenguajes dependientes del contexto en la Jerarquía de Chomsky.

\begin{thebibliography}{99}
      
      \bibitem{mainRCGBib}
      Boullier, Pierre. 
      \textit{Proposal for a Natural Language Processing Syntactic Backbone}. 
      Research Report RR-3342, INRIA, 1998. 
      
      \bibitem{propertiesRCGBib}
      Boullier, Pierre. 
      \textit{A Cubic Time Extension of Context-Free Grammars}. 
      Research Report RR-3611, INRIA, 1999. 
      
      \bibitem{simpleMatrixLanguages}
      Ibarra, Oscar H. 
      \textit{Simple matrix languages}. 
      \textit{Information and Control}, Vol. 17, No. 4, pp. 359-394, 1970. 
      
      \bibitem{globalIndexLanguages}
      Castaño, José M. 
      \textit{Global Index Languages}. 
      Ph.D. Thesis, The Faculty of the Graduate School of Arts and Sciences, Brandeis University, 2004.
      
      \bibitem{authomataTheory}
      Hopcroft, John E., Motwani, Rajeev, y Ullman, Jeffrey D. 
      \textit{Introduction to Automata Theory, Languages, and Computation}. 
      3ª edición, Addison-Wesley, 2006. ISBN: 9780321455369.
      
      \bibitem{aCFSAT}
      Fernández Arias, Alina. 
      \textit{El problema de la satisfacibilidad booleana libre del contexto}. 
      Facultad de Matemática y Computación, Universidad de La Habana, 2007.
      
      \bibitem{aSRCSAT}
      Aguilera López, Manuel. 
      \textit{Problema de la Satisfacibilidad Booleana de Concatenación de Rango Simple}. 
      Facultad de Matemática y Computación, Universidad de La Habana, 2016.
      
      \bibitem{aSMSAT}
      Rodríguez Salgado, José Jorge. 
      \textit{Gramáticas Matriciales Simples. Primera aproximación para una solución al problema SAT}. 
      Facultad de Matemática y Computación, Universidad de La Habana, 2019.
      
      \bibitem{geeksforgeeks_2sat}
      GeeksforGeeks. 
      \textit{2-Satisfiability (2-SAT) Problem}. 
      https://www.geeksforgeeks.org/2-satisfiability-2-sat-problem/, Accessed: 2025-01-09.
      
      \bibitem{geeksforgeeks_chomsky_hierarchy}
      GeeksforGeeks. 
      \textit{Chomsky Hierarchy in Theory of Computation}. 
      https://www.geeksforgeeks.org/chomsky-hierarchy-in-theory-of-computation/, Accessed: 2025-01-09.
      
      \bibitem{geeksforgeeks_finite_state_transducer}
      GeeksforGeeks. 
      \textit{Finite State Transducer (FSTs) in NLP}. 
      https://www.geeksforgeeks.org/finite-state-transducer-fsts-in-nlp/, Accessed: 2025-01-09.
      
      
      
\end{thebibliography}


\end{document}